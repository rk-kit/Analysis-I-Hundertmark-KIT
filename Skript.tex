\documentclass[11pt, twoside, a4paper]{article}

% Setup
\usepackage[margin=2.4cm, top=3.5cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}

% Package imports
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{setspace}
\usepackage{float}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage[pagestyles]{titlesec}
\usepackage{fancyhdr}
\usepackage{colonequals}
\usepackage{caption}
\usepackage{tikz}
\usepackage{marginnote}
\usepackage{etoolbox}
\usepackage{mdframed}
\usepackage{aligned-overset}

% Font-Encoding
\usepackage[T1]{fontenc}
\usepackage{lmodern}

% Theorems
\newtheorem{blockelement}{Blockelement}[subsection]
\newtheoremstyle{plain}{}{}{}{}{\bfseries}{.}{ }{}
\theoremstyle{plain}
\newtheorem{bemerkung}[blockelement]{Bemerkung}
\newtheorem{definition}[blockelement]{Definition}
\newtheorem{lemma}[blockelement]{Lemma}
\newtheorem{satz}[blockelement]{Satz}
\newtheorem{notation}[blockelement]{Notation}
\newtheorem{korollar}[blockelement]{Korollar}
\newtheorem{uebung}[blockelement]{Übung}
\newtheorem{beispiel}[blockelement]{Beispiel}
\newtheorem{folgerung}[blockelement]{Folgerung}
\newtheorem{axiom}[blockelement]{Axiom}
\newtheorem{beobachtung}[blockelement]{Beobachtung}
\newtheorem{konzept}[blockelement]{Konzept}
\newtheorem{visualisierung}[blockelement]{Visualisierung}
\newtheorem{anwendung}[blockelement]{Anwendung}
\newtheorem{skizze}[blockelement]{Skizze}

% Marginnotes left
\makeatletter
\patchcmd{\@mn@@@marginnote}{\begingroup}{\begingroup\@twosidefalse}{}{\fail}
\reversemarginpar
\makeatother

% Long equations
\allowdisplaybreaks

% \left \right
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\pair}[1]{\left(#1\right)}
\newcommand{\of}[1]{\mathopen{}\mathclose{}\bgroup\left(#1\aftergroup\egroup\right)}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\linterv}[1]{\left[#1\right)}
\newcommand{\rinterv}[1]{\left(#1\right]}
\newcommand{\interv}[1]{\left[#1\right]}
\newcommand{\sprod}[1]{\left<#1\right>}

% Shorten commands
\newcommand{\equivalent}[0]{\Leftrightarrow{}}
\newcommand{\impl}[0]{\Rightarrow{}}
\newcommand{\fromto}{\rightarrow{}}
\newcommand{\definedas}[0]{\coloneqq}
\newcommand{\definedasbackwards}[0]{\eqqcolon}
\newcommand{\definedasequiv}[0]{\ratio\Leftrightarrow{}}
\newcommand{\exclude}[0]{\setminus}
\renewcommand{\emptyset}{\varnothing}
\newcommand{\sbset}{\subseteq}

\newcommand{\ntoinf}[0]{n\fromto\infty}
\newcommand{\toinf}{\fromto\infty}
\newcommand{\fa}{\;\forall\,}
\newcommand{\ex}{\;\exists\,}
\newcommand{\conj}[1]{\overline{#1}}

\newcommand{\annot}[3][]{\overset{\text{#3}}#1{#2}}
\newcommand{\biglim}[1]{{\displaystyle \lim_{#1}}}
\newcommand{\nn}[0]{\\[2\baselineskip]}
\newcommand{\anf}[1]{\glqq{}#1\grqq}
\newcommand{\OBDA}{o.B.d.A. }
\newcommand{\theoremescape}{\leavevmode}
\newcommand{\aligntoright}[2]{\hfill#1\hspace{#2\textwidth}~}
\newcommand{\horizontalline}[0]{\par\noindent\rule{0.05\textwidth}{0.1pt}\\}
\newcommand{\rgbcolor}[3]{rgb,255:red,#1;green,#2;blue,#3}
\newcommand{\fixedspace}[2]{\makebox[#1][l]{#2}}

\let\Re\relax
\let\Im\relax

% MathOperators
\DeclareMathOperator{\grad}{Grad}
\DeclareMathOperator{\bild}{Bild}
\DeclareMathOperator{\Re}{Re}
\DeclareMathOperator{\Im}{Im}

% Mengenbezeichner
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\K}{\mathbb{K}}

\newcommand\imaginarysubsection[1]{
    \refstepcounter{subsection}
    \subsectionmark{#1}
}

% Unfassbar hässlich, aber effektiv für temporäre schnelle Lösungen
\def\:={\coloneqq}
\def\->{\fromto}
\def\=>{\impl}
\def\<={\leq}
\def\>={\geq}
\def\!={\neq}

% Envs
\newenvironment{induktionsanfang}{
    \rule{0pt}{3ex}\noindent
    \begin{minipage}[t]{0.11\textwidth}
    {I-Anfang}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.89\textwidth}
    }
    {
    \end{minipage}
}
\newenvironment{induktionsvoraussetzung}{
    \rule{0pt}{3ex}\noindent
    \begin{minipage}[t]{0.11\textwidth}
    {I-Vor.}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.89\textwidth}
    }
    {
    \end{minipage}
}
\newenvironment{induktionsschritt}{
    \rule{0pt}{3ex}\noindent
    \begin{minipage}[t]{0.11\textwidth}
    {I-Schritt}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.89\textwidth}
    }
    {
    \end{minipage}
}

% Section style
\titleformat*{\section}{\LARGE\bfseries}
\titleformat*{\subsection}{\large\bfseries}

% Page styles
\newpagestyle{pagenumberonly}{
    \sethead{}{}{}
    \setfoot[][][\thepage]{\thepage}{}{}
}
\newpagestyle{headfootdefault}{
    \sethead[][][\thesubsection~\textit{\subsectiontitle}]{\thesection~\textit{\sectiontitle}}{}{}
    \setfoot[][][\thepage]{\thepage}{}{}
}
\pagestyle{headfootdefault}

\begin{document}
    \title{\vspace{3cm} Skript zur Vorlesung\\Analysis I\\bei Prof. Dr. Dirk Hundertmark}
    \author{Karlsruher Institut für Technologie}
    \date{Wintersemester 2023/24}
    \maketitle
    \begin{center}
        Dieses Skript ist inoffiziell. Es besteht kein\\ Anspruch auf Vollständigkeit oder Korrektheit.
    \end{center}
    \thispagestyle{empty}
    \newpage

    \tableofcontents
    ~\\
    Alle mit [*] markierten Kapitel sind noch nicht korrektur gelesen und bedürfen eventuell noch Änderungen.
    \newpage


    \section{Aussagenlogik}
    \input{Kapitel/Aussagenlogik}


    \section{Mengen}
    \input{Kapitel/Mengen}


    \section{Die Axiome der reellen Zahlen}
    \input{Kapitel/Reelle_Zahlen}


    \section{Die natürlichen Zahlen $\N$ und vollständige Induktion}
    \input{Kapitel/Natuerliche_Zahlen}


    \section{Summe, Produkt, Wurzeln}
    \input{Kapitel/Summe_Produkt_Wurzeln}


    \section{Folgen und Grenzwerte}
    \input{Kapitel/Folgen_Grenzwerte}


    \section{Dichtheit von $\Q$ in $\R$}
    \input{Kapitel/Dichtheit}


    \section{[*] Reihen (und Konvergenz von Reihen)}
    \thispagestyle{pagenumberonly}

    Bedeutung von endlichen Summen ist klar.\\
    Frage: Gegeben eine reelle Folge $a_n$. Was ist $\pair{a_1 + a_2 + a_3 + \dots = \sum_{n=1}^{\infty} a_n}$?

    \subsection{[*] Konvergenz-Kriterien für Reihen}

    \begin{definition}[Reihen als Partialsummen] % Definition 1
        Das Symbol
        \begin{align*}
            \sum_{n=1}^{\infty} a_n\tag{Sei $a_n$ eine reelle Folge}
        \end{align*}
        wird folgendermaßen verwendet:

        \begin{enumerate}[label=\alph*)]
            \item Es steht für die Folge der Partialsummen:
            \begin{align*}
                s_n&\definedas \sum_{j=1}^{n} a_j\quad\forall n\in\N
            \end{align*}
            \item Die Reihe $\sum_{n=1}^{\infty} a_n$ konvergiert, falls der Grenzwert der Partialsummen $\lim_{n\fromto\infty} s_n$ existiert.\\
            Wir setzen
            \begin{align*}
                \sum_{n=1}^{\infty} a_n &\definedas \lim_{n\fromto\infty} s_n
            \end{align*}
            \item Konvergiert $(s_n)_n$ nicht, so heißt $\sum_{n=1}^{\infty} a_n$ divergent. Falls $s_n$ bestimmt divergiert so setzen wir
            \begin{align*}
                \sum_{n=1}^{\infty} a_n &\definedas \infty \tag{Wenn $\lim_{n\fromto\infty} s_n = \infty$}\\
                \sum_{n=1}^{\infty} a_n &\definedas -\infty \tag{Wenn $\lim_{n\fromto\infty} s_n = -\infty$}
            \end{align*}
        \end{enumerate}
    \end{definition}

    \begin{satz}[Monotone Konvergenz für Reihen] % Satz 2
        \label{satz:mont-konv-reihen}
        Sei $a_n$ eine reelle Folge mit $\forall n\colon a_n\geq 0$. Dann konvergiert die Reihe $\sum_{j=1}^{\infty} a_j$ genau dann, wenn die Folge der Partialsummen $s_n$ nach oben beschränkt ist.

        \begin{proof}
            Betrachte
            \begin{align*}
                s_{n+1} &= \sum_{j=1}^{n+1} a_j = \sum_{j=1}^n a_j + a_{n+1} \geq \sum_{j=1}^{n} a_j = s_n
            \end{align*}
            und wende Satz~\ref{satz:monoton-konv} an.
        \end{proof}
    \end{satz}

    \begin{korollar} % Korollar 3
        Für eine Reihe $\sum_{n=1}^{\infty} a_n$ mit $a_n\geq 0$ gilt entweder
        \begin{align*}
            \sum_{n=1}^{\infty} a_n < \infty\quad\text{oder}\quad\sum_{n=1}^{\infty} a_n = \infty
        \end{align*}

        \begin{proof}
            Folgt direkt aus Satz~\ref{satz:mont-konv-reihen}.
        \end{proof}
    \end{korollar}

    \begin{bemerkung}
        Oft hat man Reihen der Form
        \begin{align*}
            \sum_{n=0}^{\infty} a_n &= a_0+a_1+a_2+\dots\\
            s_n&\definedas \sum_{j=0}^{n} a_j \tag{$n\in\N_0$}
            \intertext{oder}
            s_n &\definedas a_0 + \sum_{j=1}^{\infty} a_j\tag{$n\in\N$}
            \intertext{Sofern ein Limes existiert, gilt dann}
            \sum_{n=0}^{\infty} a_n &\definedas \lim s_n\\[10pt]
            \intertext{Allgemein für $v\in\Z\quad a_v, a_{v+1}, a_{v+2}, \dots$}
            \sum_{n=v}^{\infty} a_n &= a_v + a_{v+1} + \dots\\
            s_n &\definedas \sum_{j=v}^{n} a_j\text{ def. Folge $(s_n)_{n\geq v}$}
        \end{align*}
    \end{bemerkung}

    \begin{beispiel}[Geometrische Folge und Reihe]
        \footnote{Wir setzen $0^0 = 1$}
        \begin{align*}
            q\neq 1 \impl \sum_{j=0}^{n} q^j = \frac{1-q^{n+1}}{1-q}\quad\forall n\in\N_0\\
            \text{Ist } \abs{q} < 1\colon \sum_{n=0}^{\infty} q^n\text{ konvergiert und } \sum_{n=0}^{\infty} q^n = \frac{1}{1-q}\tag{geometrische Reihe}
        \end{align*}
        Zum Beispiel $q=\frac{1}{2}$
        \begin{align*}
            \sum_{j=0}^{n} q^j &= \frac{1-q^{n+1}}{1-q}\\
            \equivalent \pair{1-q}\cdot \sum_{j=0}^{n} q^j &= 1-q^{n+1}\\
            \frac{1}{2}\sum_{j=0}^{n} \pair{\frac{1}{2}}^j &= 1 - \pair{\frac{1}{2}}^{n+1}\\
            \impl 1 - \pair{\frac{1}{2}}^{n+1} &= \sum_{j=0}^{n} \frac{1}{2}\cdot\pair{\frac{1}{2}}^j\\
            &= \sum_{j=0}^{n} \pair{\frac{1}{2}}^{j+1} = \sum_{j=1}^{n+1} \pair{\frac{1}{2}}^j
        \end{align*}
        Das heißt es sollte gelten
        \begin{align*}
            \sum_{j=1}^{n} \pair{\frac{1}{2}}^j &= 1-\pair{\frac{1}{2}}^n\quad \forall n\in\N
        \end{align*}

        \noindent Dass dieser Zusammenhang gelten muss, lässt sich einfach veranschaulichen. Die linke Seite der Gleichung kann als Summe über Teilflächen des Einheitsquadrats\footnote{Original: \anf{Kuchen}} visualisiert werden.\\
        Erst wird eine Hälfte, dann ein Viertel, dann ein Achtel (usw.) des Quadrats hinzugefügt. Der zurückbleibende Flächeninhalt ist immer genauso groß wie das zuletzt hinzugefügte Stück. Dieser Term wird durch den rechten Teil der Gleichung beschrieben.

        \begin{proof}[Beweis der Reihenformel]
            \begin{align*}
                s_n &\definedas \sum_{j=0}^{n} q^n\\
                q\cdot s_n &= q\cdot \sum_{j=0}^{n} q^j = \sum_{j=0}^{n} q^{j+1}\\
                &= \sum_{j=1}^{n+1} q^j\tag{Indexshift}\\
                \impl (1-q)\cdot s_n = s_n - q\cdot s_n &= \sum_{j=0}^{n}  q^j - \sum_{j=1}^{n+1} q^j\tag{Reißverschlusssumme}\\
                = q^0 - q^{n+1} &= 1 - q^{n+1}\\
                \impl s_n &= \frac{1-q^{n+1}}{1-q}\qedhere
            \end{align*}
        \end{proof}

        %%%%%%%%%%%%%%%%%%%%%%%%
        % 05. Dezember 2023
        %%%%%%%%%%%%%%%%%%%%%%%%

        \begin{proof}[Beweis der Konvergenz für $\abs{q} < 1$]
            \marginnote{[5. Dez]}
            \begin{align*}
                s_n\definedas \sum_{j=0}^{n} q^j &= \frac{1-q^{n+1}}{1-q}\\
                \lim_{n\fromto\infty} q^n &= 0 = \lim_{n\fromto\infty} q^{n+1}\tag{Weil $\abs{q} < 1$}\\
                \annot{\impl}{\ref{satz:konvergenzsaetze}} \lim s_n &= \frac{1-\lim_{n\fromto\infty} q^{n+1}}{1-q} = \frac{1-0}{1-q} = \frac{1}{1-q}\qedhere
            \end{align*}
        \end{proof}
        \begin{bemerkung}
            Ist $\abs{q}\geq 1$, dann ist $1+\underbrace{q}_{\geq 1}+\underbrace{q^2}_{\geq 1}+\underbrace{q^3}_{\geq 1}+\dots + \underbrace{q^n}_{\geq 1} \geq 1+n\fromto\infty$.
        \end{bemerkung}
    \end{beispiel}

    % TODO: Wahrscheinlichkeitstheoretische Anschauung
    \newpage

    \begin{beispiel}[Harmonische Reihe]
        \begin{align*}
            s_n &\definedas \sum_{j=1}^{n} \frac{1}{j}
        \end{align*}
        $(s_n)_n$ ist monoton wachsend, aber nicht nach oben beschränkt. Das heißt $\lim_{n\fromto\infty} s_n = \infty \impl \sum_{n=1}^{\infty} \frac{1}{n} = \infty$.

        \begin{proof}
            \begin{align*}
                s_{2n} - s_n &= \sum_{j=n+1}^{2n} \frac{1}{j} \geq \sum_{j=n+1}^{n} \frac{1}{2n} = n \cdot\frac{1}{2n} = \frac{1}{2}\\
                \impl s_2 - s_1 &\geq \frac{1}{2}\\
                \impl s_2 &\geq s_1 + \frac{1}{2} = 1 + \frac{1}{2} > \frac{1}{2}\\
                s_4 - s_2 &\geq \frac{1}{2}\\
                \impl s_4 &\geq s_2 + \frac{1}{2} > \frac{1}{2} + \frac{1}{2} = 1\\
                s_8 - s_4 &\geq \frac{1}{2}\\
                \impl s_8 &\geq s_4 + \frac{1}{2} \geq \frac{3}{2}\\
                \annot{\impl}{Induktion} s_{\pair{2^j}} &> \frac{j}{2}\quad\forall j\in\N
            \end{align*}
            \noindent Also ist $s_{\pair{2^j}}$ nicht nach oben beschränkt $\impl$ $(s_n)_n$ nicht nach oben beschränkt.
            \begin{align*}
                \annot{\impl}{\ref{satz:monoton-konv}} \sum_{n=1}^{\infty} \frac{1}{n} = \lim_{n\fromto\infty} s_n &= +\infty\qedhere
            \end{align*}
        \end{proof}
    \end{beispiel}

    \begin{satz} % Satz 6
        Seien $\sum_{n=1}^{\infty} a_n$, $\sum_{n=1}^{\infty} b_n$ konvergente Reihen. Dann ist
        \begin{align*}
            \forall\lambda, \mu \in\R\colon \sum_{n=1}^{\infty} \pair{\lambda\cdot a_n + \mu\cdot b_n}
        \end{align*}
        konvergent und es gilt
        \begin{align*}
            \sum_{n=1}^{\infty} \pair{\lambda\cdot a_n + \mu\cdot b_n} = \lambda \cdot \sum_{n=1}^{\infty} a_n + \mu\cdot \sum_{n=1}^{\infty} b_n
        \end{align*}
        \begin{proof}
            \begin{align*}
                s_n &\definedas \sum_{j=1}^{n} a_n \quad t_n \definedas \sum_{j=1}^{n} b_n\\
                d_n &\definedas \sum_{j=1}^{n} \pair{\lambda\cdot a_n + \mu\cdot b_n} =   \lambda \cdot \sum_{n=1}^{n} a_n + \mu\cdot \sum_{n=1}^{n} b_n\\
                &= \lambda\cdot s_n + \mu\cdot t_n \fromto \lambda\cdot s + \mu\cdot t\tag{Mit $s$ und $t$ als Limes}
            \end{align*}
        \end{proof}
    \end{satz}

    \newpage

    \begin{satz}[Majoranten-Kriterium] % Satz 7
        \label{satz:majoranten-kriterium}
        Gegeben zwei Folgen $0\leq a_n \leq b_n~\forall n\in\N$. Konvergiert
        \begin{align*}
            \sum_{n=1}^{\infty} b_n\quad\text{so konvergiert auch}\quad\sum_{n=1}^{\infty} a_n
        \end{align*}
        und es gilt
        \begin{align*}
            0\leq \sum_{n=1}^{\infty} a_n \leq \sum_{n=1}^{\infty} b_n
        \end{align*}
        \begin{proof}
            \begin{align*}
                &s_n = \sum_{j=1}^{n} a_j\quad t_n = \sum_{j=1}^{n} b_j\\
                \impl &s_{n+1} = s_n + a_{n+1} \geq s_n\\
                &t_{n+1} = t_n + b_{n+1} \geq t_n\\
                \impl &(s_n)_n,~(t_n)_n\text{ sind monoton wachsend}\\
                \intertext{Mit der Konvergenz von $(t_n)_n$ und $(t_n)_n$ monoton wachsend folgt mit Satz~\ref{satz:mont-konv-reihen}}
                \impl &(t_n)_n\text{ ist beschränkt}\\
                \impl &\exists M\geq 0\colon t_n \leq M\quad\forall n\in\N\\
                0\leq a_n \leq b_n \impl &0\leq s_n \leq t_n \leq M \quad\forall n\in\N\\
                \impl &(s_n)_n\text{ ist nach oben beschränkt und monoton wachsend}\\
                \annot{\impl}{\ref{satz:mont-konv-reihen}} &\lim_{n\fromto\infty} s_n\text{ existiert }\\
                \quad s &\definedas \lim_{n\fromto\infty} s_n \leq \lim_{n\fromto\infty} t_n = \sum_{n=1}^{\infty} b_n\qedhere\\
                \intertext{Außerdem gilt:}
                t_n - s_n &= \sum_{j=1}^{n} b_j - \sum_{j=1}^{n} a_j = \sum_{j=1}^{n} n \pair{b_j-a_j} \geq 0
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{satz}[Minoranten-Kriterium] % Satz 8
        Sei $0\leq b_n \leq a_n~\forall n\in\N$ und
        \begin{align*}
            \sum_{n=1}^{\infty} b_n &= \infty\\
            \impl \sum_{n=1}^{\infty} a_n&\text{ divergiert auch bestimmt gegen }\infty
        \end{align*}
        \begin{proof}
            \begin{align*}
                t_n &= \sum_{j=1}^{n} b_n \quad s_n = \sum_{j=1}^{n} a_n
                \intertext{Analog zum Beweis des Majoranten-Kriteriums gilt:}
                (s_n)_n,~(t_n)_n&\text{ sind monoton wachsend und }t_n \leq s_n \quad\forall n\in\N
                \intertext{Dann lässt sich folgern}
                \sum_{n=1}^{\infty} b_n = \infty &\equivalent (t_n)_n \text{ wächst über alle Grenzen}\\
                &\impl (s_n)_n\text{ wächst über alle Grenzen}\\
                &\impl \lim_{n\fromto\infty} s_n = \infty = \sum_{n=1}^{\infty} a_n\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{beispiel}[Anwendung des Minoranten-Kriteriums]
        Es sei
        \begin{align*}
            a_n\geq \frac{c}{n}\quad\forall n\in\N\tag{$c>0$}
            \intertext{Nach Minorantenkriterium und der Divergenz der harmonischen Reihe gilt}
            \impl \sum_{n=1}^{\infty} a_n = \infty
        \end{align*}
    \end{beispiel}
    \begin{beispiel}[Anwendung des Majoranten-Kriteriums]
        Es sei wieder $c>0$. Dann folgt aus
        \begin{align*}
            0\leq a_n \leq c\cdot q^n\land 0\leq q < 1
            \intertext{nach Majoranten-Kriterium und dem Konvergenzkriterium der geometrischen Reihe, dass}
            \impl \sum_{n=1}^{\infty} a_n\text{ konvergiert}\tag{$b_n=c\cdot q^n$}
        \end{align*}
    \end{beispiel}

    \begin{bemerkung}[Abgeschwächtes Majoranten-Kriterium]
        Die Konvergenz/Divergenz von Reihen (und Folgen) ändert sich nicht, wenn man endlich viele Summanden (Folgeglieder) abändert.\\
        Für das Majoranten-Kriterium reicht also, dass $0\leq a_n \leq b_n$ für fast alle $n\in\N$, damit
        \begin{align*}
            \sum_{n=1}^{\infty} b_n\text{ konvergiert }\impl \sum_{n=1}^{\infty} a_n\text{ konvergiert}
        \end{align*}
        Das gleiche gilt analog für das Minoranten-Kriterium
    \end{bemerkung}

    \newpage

    \begin{satz}[Cauchyscher Verdichtungssatz] % Satz 9
        \label{satz:cauchy-verdichtung}
        Sei $(a_n)_n$ eine monoton fallende Nullfolge. Dann gilt
        \begin{align*}
            &\sum_{n=0}^{\infty} a_n\text{ konvergiert}\\
            \equivalent &\sum_{n=0}^{\infty} 2^n\cdot a_{\pair{2^n}}\text{ konvergiert}\tag{Verdichtete Reihe}
        \end{align*}
        \begin{proof}
            \anf{$\Leftarrow$} 1. Schritt. Zu zeigen: $a_n\geq 0\quad\forall n\in\N$.
            \begin{align*}
                a_n&\geq a_{n+1} \geq a_{n+2} \geq \dots \geq a_{n+l} \fromto 0\text{ für } l\fromto\infty\\
                \impl a_n &\geq 0\quad\forall n\in\N
            \end{align*}
            2. Schritt:
            \begin{align*}
                s_n &\definedas \sum_{j=0}^{n} a_j\\
                t_n &\definedas \sum_{\nu=0}^{n} 2^{\nu} \cdot a_{\pair{2^\nu}}
                \intertext{Jedes $\overline{n}\in\N$ können wir eindeutig schreiben als $\overline{n}=2^\nu + l$ mit $\nu\in\N_0,~0\leq l < 2^\nu$~\footnotemark.\endgraf \noindent Sei $1\leq n< 2^k$ für ein $k\in\N_0$}
                s_n &= \sum_{j=0}^{n} a_j = a_0 + \sum_{j=1}^{n} a_j\\
                &\leq a_0 + \sum_{j=1}^{2^k-1} a_j = a_0 + \sum_{\nu=0}^{k-1} \pair{\sum_{l=0}^{2^\nu - 1} \underbrace{a_{\pair{2^\nu + l}}}_{\leq a_{\pair{2^\nu}}}}\\
                &\leq a_0 + \sum_{\nu=0}^{k-1} \pair{\sum_{l=0}^{2^\nu-1} a_{\pair{2^\nu}}}\\
                &= a_0 + \sum_{\nu = 0}^{k-1} 2^{\nu}\cdot a_{\pair{2^\nu}}\\
                &= a_0 + t_{k-1}\\[10pt]
                \impl &\forall n < 2^k\text{ gilt }s_n\leq a_0 + t_{k-1}
            \end{align*}
            \footnotetext{Es lässt sich zeigen, dass $l$ und $\nu$ in diesem Fall eindeutig sind.}
            Angenommen
            \begin{align*}
                \sum_{\nu = 0}^{\infty} 2^{\nu} \cdot a_{2^\nu}\text{ konvergent} &\equivalent \lim_{n\fromto\infty} t_n = t\text{ existiert}\\
                &\impl s_n \leq a_0 + \lim_{k\fromto\infty} t_{k-1} = a_0 + t\quad\forall n\in\N
                \intertext{Somit ist $a_0 + l$ eine obere Schranke von $(s_n)_n$. Da $s_n\leq s_{n+1} \annot{\impl}{\ref{satz:monoton-konv}} \lim_{n\fromto\infty} s_n$ existiert}
                \impl \sum_{n=0}^{\infty} a_n&\text{ konvergent}
            \end{align*}
            \anf{$\impl$} Sei $n\geq 2^k$
            \begin{align*}
                s_n &= \sum_{j=0}^{n} a_j \geq \sum_{j=0}^{2^k} a_j\\
                &= \sum_{\nu=0}^{k} \pair{\sum_{l=0}^{2^\nu-1} \underbrace{a_{\pair{2^\nu + l}}}_{\geq a_{\pair{2^\nu+1}}}}\\
                &\geq \sum_{\nu=0}^{k} \pair{\sum_{l=0}^{2^\nu-1} a_{\pair{2^\nu+1}}} = \sum_{\nu=0}^{k} 2^{\nu}\cdot a_{\pair{2^\nu}} + 1\\
                &= \sum_{\nu = 1}^{k+1} 2^{\nu-1} a_{\pair{2^\nu}} = \frac{1}{2}\sum_{\nu=1}^{k+1} 2^{\nu} a_{\pair{2^\nu}}\\
                &= \frac{1}{2}\pair{\sum_{\nu=0}^{k+1} 2^\nu a_{\pair{2^\nu}} - a_0}\\
                &= t_{k+1} - a_0\\
                \impl t_k \leq t_{k+1} &\leq s_n + a_0\quad\forall 2^k \geq n\\
                \impl t_k &\leq \lim_{n\fromto\infty} s_n + a_0 = s + a_0 < \infty\\
                \text{sofern} \sum_{n=0}^{\infty} a_0\text{ konvergiert}
            \end{align*}
            Da $t_k < t_{k+1}$ konvergiert, konvergiert auch $\sum_{\nu=0}^{\infty} 2^\nu \cdot a_{2^\nu}$
        \end{proof}
    \end{satz}

    \begin{beispiel}[Cauchyscher Verdichtungssatz als Konvergenzkriterium]
        Es sei
        \begin{align*}
            a_n &= \frac{1}{n^\alpha}\\
            2^{n} \cdot a_{\pair{2^\nu}} &= \frac{2^n}{(2^n)^\alpha} = \frac{2^n}{2^{n\cdot\alpha}}\\
            &= 2^{n-n\cdot\alpha} = 2^{(1-\alpha)\cdot n} = \pair{2^{1-\alpha}}^n = q^n
            \intertext{Damit $q^n$ und damit auch $(a_n)_n$ konvergiert muss wie bereits gezeigt gelten}
            q &\definedas 2^{1-\alpha} < 1 \equivalent 1-\alpha < 0 \equivalent \alpha > 1
            \intertext{Es sei}
            a_n &= \frac{1}{n}\\
            2^n \cdot a_{\pair{2^\nu}} &= 2^n \cdot \frac{1}{2^n} = 1\impl (a_n)_n\text{ konvergiert}
        \end{align*}
    \end{beispiel}

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 7. Dezember 2023
    %%%%%%%%%%%%%%%%%%%%%%%%

    \begin{definition}[Alternierende Reihe] % Definition 10
        \marginnote{[7. Dez]}
        Sei $(a_n)_n$ eine reelle Folge nicht-negativer reeller Zahlen. Dann heißt
        \begin{align*}
            \sum_{n=1}^{\infty} (-1)^{n+1} \cdot a_n = a_1 - a_2 + a_3 - a_4 \dots
        \end{align*}
        alternierende Reihe. Alternativ $a_n\geq 0$, $n\in\N_0$.
        \begin{align*}
            \sum_{n=0}^{\infty} (-1)^n\cdot a_n = a_0 - a_1 + a_2 - a_3 \dots
        \end{align*}
    \end{definition}

    \begin{satz}[Leibniz-Kriterium] % Satz 11
        Sei $(a_n)_n$ eine monoton fallende Nullfolge. Dann konvergiert
        \begin{align*}
            \sum_{n=1}^{\infty} (-1)^{n+1} \cdot a_n
        \end{align*}

        \begin{proof}
            Idee: Wir unterscheiden zwischen geraden und ungeraden $n$.
            \begin{align*}
                s_n &\definedas \sum_{j=1}^{n} (-1)^{j+1} \cdot a_j\\
                s_{2(n+1)} &= \sum_{j=1}^{2n+2} (-1)^{j+1} \cdot a_j\\
                &= \sum_{j=1}^{2n} (-1)^{j+1} \cdot a_j + (-1)^{(2n+1)+1} \cdot a_{2n+1} + (-1)^{(2n+2)+1} \cdot a_{2n+2}\\
                &= s_{2n} + \underbrace{a_{2n+1} - a_{2n+2}}_{\geq 0}\\
                &\geq s_{2n}
                \intertext{Also ist $(s_{2n})_n$ monoton wachsend}
                s_{2(n+1)+1} &= s_{2n+3} = \sum_{j=1}^{2n+3} (-1)^{j+1} \cdot a_j\\
                &= s_{2n+1} + (-1)^{(2n+2)+1} \cdot a_{2n+2} + (-1)^{(2n+3)+1} \cdot a_{2n+3}\\
                &= s_{2n+1} \underbrace{- a_{2n+2} + a_{2n+3}}_{\leq 0}\\
                &\leq s_{2n+1}
            \end{align*}
            Also ist $(s_{2n+1})_n$ ist monoton fallend und
            \begin{align*}
                s_{2n+1} - s_{2n} &= \sum_{j=1}^{2n+1} (-1)^{j+1} \cdot a_j - \sum_{j=1}^{2n} (-1)^{j+1}\cdot a_j\\
                &= (-1)^{(2n+1)+1} \cdot a_{2n+1} = a_{2n+1} \geq 0
                \intertext{$\impl \abs{s_{2n+1}-s_{2n}} = a_{2n+1}$ und $s_{2n+1} \geq s_{2n}$}
                0 \leq a_1 - a_2 &= s_2 \leq s_{2n} \leq s_{2n+1} \leq s_1 = a_1\\
                \annot{\impl}{\ref{satz:monoton-konv}} s_g &\definedas \lim_{n\fromto\infty} s_{2n}\text{ existiert}\\
                s_u &\definedas \lim_{n\fromto\infty} s_{2n-1}\text{ existiert}\\
                \text{und } s_g &= s_u\\
                \impl (s_n)_n&\text{ konvergiert gegen $s=s_g=s_u$}\qedhere
            \end{align*}
        \end{proof}
        \begin{uebung}
            Weisen Sie nach, dass eine Folge konvergiert, wenn die Teilfolgen der geraden und der ungeraden Folgeglieder konvergieren und die Differenz eine Nullfolge ist.
        \end{uebung}
    \end{satz}

    \begin{beispiel}
        \begin{align*}
            &\sum_{n=1}^{\infty} \pair{-1}^{n+1} \cdot \frac{1}{\sqrt{n}}\text{ konvergiert}\\
            \text{aber } &\sum_{n=1}^{\infty} \frac{1}{\sqrt {n}} \text{ divergiert}\\
            &\sum_{n=1}^{\infty} (-1)^{n} \cdot \frac{1}{n}\text{ konvergiert}\\
            &\sum_{n=2}^{\infty} (-1)^n \cdot \frac{1}{\log\pair{n}}\text{ konvergiert}
        \end{align*}
    \end{beispiel}

    \begin{satz}[Cauchy-Kriterium] % Satz 12
        \label{satz:cauchy-kriterium}
        Sei $(a_n)_n$ eine Folge reeller Zahlen. Dann konvergiert
        \begin{align*}
            \sum_{n=1}^{\infty} a_n
        \end{align*}
        genau dann, wenn
        \begin{align*}
            \forall \varepsilon > 0~\exists N_{\varepsilon}\in\N\colon \abs{\sum_{j=n+1}^{m} a_j} <\varepsilon\quad\forall m>n\geq N_{\varepsilon}
        \end{align*}
        \begin{proof}
            \begin{align*}
                s_n &\definedas \sum_{j=1}^{n} a_j\\
                \intertext{$(s_n)_n$ konvergiert nach Satz~\ref{satz:jede-konv-cauchy} genau dann, wenn es eine Cauchy-Folge ist. Das heißt}
                \forall\varepsilon > 0~\exists N_{\varepsilon}\in\N\colon &\abs{s_{m} - s_{n}} < \varepsilon\quad\forall m> n \geq N_{\varepsilon}\\
                \abs{s_m - s_n} &= \sum_{j=1}^{m} a_j = \sum_{j=1}^{n} a_j\\
                &= \sum_{j=n+1}^{m} a_j\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{korollar} % Korollar 12
        \label{korollar:folge-von-reihe-nullfolge}
        Ist die reelle Reihe $\sum_{n=1}^{\infty} a_n$ konvergent, so ist $(a_n)_n$ eine Nullfolge.
        \begin{proof}
            Nach Satz~\ref{satz:cauchy-kriterium} $\impl$
            \begin{align*}
                \forall \varepsilon > 0~\exists N_{\varepsilon}\in\N\colon &\abs{\sum_{j=n+1}^{n+p} a_j} < \varepsilon\quad\forall n\geq N_{\varepsilon}, p\in\N\\
                \intertext{Wähle $p=1$}
                \sum_{j=n+1}^{n+1} a_{j} &= a_{j+1}\\
                \impl \abs{a_{n+1}} &< \varepsilon\quad \forall n\geq N_{\varepsilon}\\
                \impl \lim_{\ntoinf} a_{n+1} &= 0\\
                \impl \lim_{\ntoinf} a_{n} &= 0\qedhere
            \end{align*}
        \end{proof}
    \end{korollar}

    \subsection{[*] Absolut konvergente Reihen und Umordnungen}

    \begin{definition}[Absolute Konvergenz] % Definition 1
        Eine Reihe$\sum_{n=1}^{\infty} a_n$ heißt absolut konvergent, falls
        \begin{align*}
            \sum_{n=1}^{\infty} \abs{a_n}
        \end{align*}
        konvergiert. Das heißt falls
        \begin{align*}
            \sum_{n=1}^{\infty} \abs{a_n} < \infty
        \end{align*}
    \end{definition}

    \begin{satz}[Absolute Konvergenz als Konvergenzkriterium] % Satz 2
        \label{satz:absolut-konvergenz-konvergenkriterium}
        Ist eine Folge $\sum_{n}^{\infty} a_n$ absolut konvergent, so ist sie auch konvergent und
        \begin{align*}
            \abs{\sum_{n=1}^{\infty} a_n} \leq \sum_{n=1}^{\infty} \abs{a_n}
        \end{align*}

        \begin{proof}
            Wir haben für $m>n$
            \begin{align*}
                \abs{\sum_{j=n+1}^{m} a_j} \leq \sum_{j=n+1}^{m} \abs{a_j}
            \end{align*}
            Wir nehmen an, dass $\sum_{n=1}^{\infty} \abs{a_n}$ konvergiert. Das heißt Cauchy ist erfüllt.
            \begin{align*}
                \impl \forall \varepsilon > 0~\exists N_{\varepsilon}\colon \sum_{j=n+1}^{m} \abs{a_j} &< \varepsilon \quad\forall m> n\geq N_{\varepsilon}\\
                \impl \abs{\sum_{j=n+1}^{m} a_j} &< \varepsilon\quad\forall m>n\geq N_{\varepsilon}\\
                \impl \sum_{j=1}^{\infty} a_j&\text{ konvergiert}\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{beispiel}[Konvergenz ohne absolute Konvergenz]
        \begin{align*}
            \sum_{n=1}^{\infty} (-1)^{n+1}\cdot \frac{1}{n}
        \end{align*}
        ist konvergent, aber nicht absolut konvergent.
    \end{beispiel}

    \begin{definition}[Majorante] % Def 3
        Die Reihe
        \begin{align*}
            \sum_{n=1}^{\infty} c_n\quad c_n\geq 0~\forall n\in\N
        \end{align*}
        ist eine Majorante der Reihe $\sum_{n}^{\infty} a_n$ falls
        \begin{align*}
            \abs{a_n} &\leq c_n\text{ für fast alle }n\in\N
            \intertext{Das heißt}
            \exists n_0\in\N\colon \abs{a_n} &< c_n\quad\forall n\geq n_0
        \end{align*}
    \end{definition}

    \begin{satz}[Majoranten-Konvergenz-Kriterium für Reihen] % Satz 4
        \label{satz:majorante-reihen}
        Hat die Reihe $\sum_{n=1}^{\infty} a_n$ eine konvergente Majorante $\sum_{n=1}^{\infty} c_n$, so ist diese Reihe absolut konvergent und somit auch konvergent.
        \begin{proof}
            Folgt aus Satz~\ref{satz:absolut-konvergenz-konvergenkriterium} und Satz~\ref{satz:majoranten-kriterium}.
        \end{proof}
    \end{satz}

    \begin{satz}[Quotientenkriterium] % Satz 5
        \label{satz:quotientenkriterium}
        Sei
        \begin{align*}
            s_n &\definedas \sum_{n=0}^{\infty} a_n
        \end{align*}
        eine Reihe mit $a_n\neq 0$. Ferner gebe es ein $0\leq q < 1$ so dass
        \begin{align*}
            \frac{\abs{a_{n+1}}}{\abs{a_n}} \leq q\text{ für fast alle } n\in\N\\
            \impl \sum_{n=0}^{\infty} a_n\text{ absolut konvergent}
        \end{align*}

        \begin{proof}
            Wir haben $n_0\in\N$
            \begin{align*}
                \frac{\abs{a_{n+1}}}{\abs{a_n}} &\leq q\quad\forall n\geq n_0\\[10pt]
                \abs{a_{n+1}} \leq q\cdot\abs{a_n} &\leq q^2 \cdot \abs{a_{n-1}} \leq q^3 \cdot \abs{a_{n-2}}\\[10pt]
                \leq \dots &\leq q^{p+1} \cdot\abs{a_{n_0}} = q^{n-n_0+1} \cdot\abs{a_{n_0}}\tag{$p\in\N$, $n=n_0+p$}\\[10pt]
                &= q^{n+1} \cdot q^{-n_0} \cdot\abs{a_{n_0}}\\[10pt]
                \impl \abs{a_n} &\leq \underbrace{q^n \cdot K}_{\definedasbackwards c_n}\tag{$K \definedas q^{-n_0} \cdot \abs{a_{n_0}}$}\\
                \impl \abs{a_{n_0}} &\leq c_n\quad\forall n\geq n_0\\
                \intertext{und}
                \sum_{n=0}^{\infty} c_n &= \sum_{n=0}^{\infty} K\cdot q^{n} = K\cdot \sum_{n=0}^{\infty} q^{n} < \infty
                \intertext{Da $0< q < 1$}
                \impl \sum_{n=c}^{\infty} &a_n\text{ hat die konvergente Majorante } K \cdot \sum_{n=c}^{\infty} q^{n}
            \end{align*}
            Damit lässt sich aus Satz~\ref{satz:majorante-reihen} folgern, dass die Reihe konvergiert.
        \end{proof}
    \end{satz}

    \begin{bemerkung}[Quotientenkriterium über $\limsup$ und $\liminf$]
        \theoremescape
        \begin{enumerate}[label=(\roman*)]
            \item Ist $\limsup_{n\fromto\infty} \frac{\abs{a_{n+1}}}{\abs{a_n}} < 1 \equivalent$ Quotientenkriterium
            \item Ist $\liminf_{n\fromto\infty} \frac{\abs{a_{n+1}}}{\abs{a_n}} > 1\impl \sum_{n=0}^{\infty} a_n$ divergent
            \item Ist $\limsup_{n\fromto\infty} \frac{\abs{a_{n+1}}}{\abs{a_n}} = 1\impl \text{Keine Aussage über absolute Konvergenz von } \sum_{n=0}^{\infty} a_n$ möglich
        \end{enumerate}
        \begin{proof}[Beweis (ii).]
            \begin{align*}
                \text{Ist } \overline{q}\definedas\liminf_{n\fromto\infty} \frac{\abs{a_{n+1}}}{\abs{a_n}} &> 1\\[8pt]
                \impl \forall \varepsilon > 0~\exists n_0\colon \frac{\abs{a_{n+1}}}{\abs{a_n}} \geq \overline{q} - \varepsilon = \frac{\overline{q}+1}{2} &\:= q > 1\tag{Wähle $\varepsilon=\frac{\overline{q}-1}{2} > 0$}\\[8pt]
                \impl \frac{\abs{a_n+1}}{\abs{a_n}} &\geq q > 1\quad\forall n\geq n_0
                \intertext{Wir wenden ein ähnliches Prinzip wie im vorherigen Beweis an}
                \impl \abs{a_{n+1}} &\geq q^{n+1} \cdot q^{-n_0}\cdot\abs{a_{n_0}}\\[8pt]
                \impl \abs{a_n} &\geq q^n\cdot K\tag{$K=q^{-n_0}\cdot\abs{a_{n_0}}$}\\[8pt]
                \impl \sum a_j\text{ divergiert nach}&\text{ Korollar~\ref{korollar:folge-von-reihe-nullfolge}}\qedhere
            \end{align*}
        \end{proof}
    \end{bemerkung}

    \begin{beispiel}[Divergenz bei nicht-eindeutigem Quotientenkriterium]
        $a_n \definedas \frac{1}{n}$
        \begin{align*}
            \frac{\abs{a_{n+1}}}{\abs{a_n}} = \frac{a_{n+1}}{a_n} &= \frac{n}{n+1} = 1 + \frac{1}{n} \fromto 1
            \intertext{Und}
            \sum_{n=1}^{\infty} \frac{1}{n}&\text{ divergiert (Harmonische Reihe)}
        \end{align*}
    \end{beispiel}

    \begin{beispiel}[Konvergenz bei nicht-eindeutigem Quotientenkriterium]
        $a_n \definedas \frac{1}{n^2}$
        \begin{align*}
            \frac{a_{n+1}}{a_n} = \frac{n^2}{(n+1)^2} &= \pair{\frac{n}{n+1}}^2 = \pair{1-\frac{1}{n+1}}^2 \fromto 1
            \intertext{Aber}
            \sum_{n=1}^{\infty} &a_n
            \intertext{konvergiert absolut:}
            \pair{1-\frac{1}{n}}^2 &= 1 - \frac{2}{n+1}+ \pair{\frac{1}{n+1}}^2\\
            &= 1 - \frac{2}{n+1}\cdot\pair{1-\frac{1}{2(n+1)}}\\
            &\leq 1- \frac{s-\delta}{n+1}\tag{Für $\delta>0$ und fast alle $n$}
        \end{align*}
    \end{beispiel}

    \newpage

    \begin{beispiel}[Eulersche Zahl über Reihendarstellung]
        Die Reihe
        \begin{align*}
            \sum_{n=0}^{\infty} \frac{1}{n!}
        \end{align*}
        ist absolut konvergent.
        \begin{align*}
            a_n &= \frac{1}{n!}\\
            \frac{a_{n+1}}{a_n} &= \frac{n!}{(n+1)!} = \frac{1}{n+1}\fromto 0
        \end{align*}
        Behauptung:
        \begin{align*}
            e'\definedas\sum_{n=0}^{\infty} \frac{1}{n!} &= e\tag{Eulersche Zahl}
        \end{align*}
        \begin{proof}
            Wir wenden die bereits gezeigt Formel für $e$ an:
            \begin{align*}
                e &= \lim_{\ntoinf} \pair{1+\frac{1}{n}}^n\\[10pt]
                \pair{1+\frac{1}{n}}^n &= \sum_{k=0}^{n}\binom{n}{k} \pair{\frac{1}{n}}^k\\
                &= \sum_{k=0}^{n} \frac{n\cdot(n-1)\cdot(n-k+1)}{k!\cdot n^k}\\
                &= \sum_{k=0}^{n} \frac{1}{k!} \cdot \prod_{j=0}^{k-1} \frac{n-j}{n}\\
                &\leq \sum_{k=0}^{n} \frac{1}{k!} \leq \sum_{k=0}^{\infty} \frac{1}{k!}\\[10pt]
                \impl e &\leq \sum_{n=0}^{\infty} \frac{1}{n!}
                \intertext{Noch zu zeigen: $e'\leq e$}
                \pair{1+\frac{1}{n}}^n &= \sum_{k=0}^{n} \frac{1}{k!} \cdot \prod_{j=0}^{k-1} 1-\frac{j}{n}\\
                &\geq \sum_{k=0}^{m} \frac{1}{k!}\cdot \prod_{j=0}^{k-1} \pair{1-\frac{j}{n}}\tag{$\forall n>m$}\\
                \intertext{Wir halten $m\in\N$ fest}
                \impl e &= \lim_{\ntoinf} \pair{1+\frac{1}{n}}^n \geq \lim_{\ntoinf} \sum_{k=0}^{m} \frac{1}{k!}\cdot \prod_{j=0}^{k-1} \pair{1-\frac{j}{n}}\\
                &= \sum_{k=0}^{m} \frac{1}{k!} \cdot \prod_{j=0}^{k-1} \underbrace{\lim_{\ntoinf} \pair{1-\frac{j}{n}}}_{=1}\\
                &= \sum_{n=0}^{m} \frac{1}{k!}\tag{$\forall m\in\N$}\\
                \impl e&\geq \lim_{\ntoinf} \sum_{k=0}^{m} \frac{1}{k!} = \sum_{k=0}^{\infty} \frac{1}{k!} = e\\
                \impl e &\leq e' \land e'\leq e\\
                \impl e &= e'\qedhere
            \end{align*}
        \end{proof}

        %%%%%%%%%%%%%%%%%%%%%%%%
        % 12. Dezember 2023
        %%%%%%%%%%%%%%%%%%%%%%%%

        \begin{bemerkung}[Ännäherung von $e$ über Reihen]
            \marginnote{[12. Dez]}
            \begin{align*}
                s_n &\definedas \sum_{k=0}^{n} \frac{1}{k!}\\
                r_{n,p} &\definedas \sum_{k=n+1}^{n+p} \frac{1}{k!}\\
                r_{n,p} &= \sum_{k=n+1}^{n+p} \frac{1}{k!} = \frac{1}{(n+1)!} + \frac{1}{(n+2)!} + \dots + \frac{1}{(n+p)!}\\
                &= \frac{1}{(n+1)!}\cdot\interv{1+\frac{1}{n+2}+\frac{1}{(n+2)\cdot(n+3)} + \dots + \frac{1}{(n+2)\cdot(n+3)\cdot\ldots\cdot(n+p)}}\\
                &> \frac{1}{(n+1)!}
                \intertext{Wir betrachten den zweiten Faktor}
                &1+\frac{1}{n+2}+\frac{1}{(n+2)\cdot(n+3)} + \dots + \frac{1}{(n+2)\cdot(n+3)\cdot\ldots\cdot(n+p)}\\
                &< 1 + \frac{1}{2} + \frac{1}{2\cdot 3}+\dots + \frac{1}{2\cdot 3 \cdot\ldots\cdot p}\\
                &= \sum_{k=0}^{p} \frac{1}{k!} - 1 < \sum_{k=0}^{\infty} \frac{1}{k!} - 1 = e-1
                \intertext{Wir kombinieren die Abschätzung über beide Faktoren und erhalten}
                \impl &\frac{1}{(n+1)!} < r_{n,p} < \frac{e-1}{(n+1)!}\\
                \equivalent &\frac{1}{(n+1)!} < s_{n+p} - s_{n} < \frac{e-1}{(n+1)!}\\
                &s_{n+p} - s_{n} \fromto e - s_n\text{ für }p\fromto\infty\\
                \impl &\frac{1}{(n+1)!} \leq e - s_n \leq \frac{e-1}{(n+1)!}
                \intertext{Wir erhalten also ein Verfahren, um einen Näherungswert für $e$ zu bestimmen}
                &2,5 \leq e \leq 3\quad(n=1)\\
                &2,66 \leq e \leq 2,8\quad(n=2)\\
                \vdots\\
                &e = 2,71828182\ldots
            \end{align*}
        \end{bemerkung}
    \end{beispiel}


    \begin{bemerkung}[Ausblick: Definition von Exponentialfunktionen über Reihen]
        \begin{align*}
            a_n &\definedas\sum_{n=0}^{\infty} \frac{x^n}{n!}\\
            \frac{\abs{a_{n+1}}}{\abs{a_n}} &= \abs{\frac{x^{n+1}\cdot n!}{(n+1)!\cdot x^n}} = \frac{\abs{x}}{n+1}\fromto 0
        \end{align*}
        Diese Konvergenz werden wir in einem späteren Kapitel nutzen, um die Exponentialfunktion über
        \begin{align*}
            \exp(x) &= \sum_{k=0}^{\infty} \frac{x^n}{n!} = e^x
        \end{align*}
        zu definieren.
    \end{bemerkung}

    \begin{satz}[Nach Lambert 1707] % Satz 7
        Die eulersche Zahl $e$ ist irrational.
        \begin{proof}
            Wir haben
            \begin{align*}
                \frac{1}{(n+1)!} &\leq e-s_n \leq \frac{e-1}{(n+1)!} < \frac{2}{(n+1)!}
                \intertext{Angenommen $e=\frac{p}{q}$\quad$p,q\in\N$. Wir nehmen $p=q\cdot m$}
                \impl \frac{1}{(q+1)!} &\leq \frac{p}{q} - s_q < \frac{2}{(q+1)!}\\
                0 &< \frac{1}{q+1} \leq \frac{p}{q}\cdot q! - q!\cdot s_q < \frac{2}{q+1}<1
                \intertext{Es lässt sich zeigen, dass der dritte Term eine ganze Zahl ist:}
                \frac{p}{q}\cdot q! &= p\cdot(q-1)!\in\N\\
                q!\cdot s_q &= q! \cdot \sum_{k=0}^{q} \frac{1}{k!}\in\N
            \end{align*}
            Damit ergibt sich ein Widerspruch, weil keine ganze Zahl zwischen $0$ und $1$ liegt.
        \end{proof}
    \end{satz}

    \newpage

    \begin{satz}[Wurzelkriterium] % Satz 8
        \label{satz:wurzelkriterium}
        Sei $(a_n)_n$ eine reelle Folge.
        \begin{enumerate}[label=(\roman*)]
            \item Ist $\limsup_{\ntoinf} \sqrt[n]{\abs{a_n}} < 1$, dann konvergiert $\sum_{n=0}^{\infty} a_n$ absolut.
            \item Ist $\limsup_{\ntoinf} \sqrt[n]{\abs{a_n}} > 1$, dann ist $\sum_{n=0}^{\infty} a_n$ divergent.
            \item Ist $\limsup_{\ntoinf} \sqrt[n]{\abs{a_n}} = 1$, so ist keine Aussage möglich.
        \end{enumerate}
        \begin{proof}[Beweis (iii)]
            \begin{align*}
                a_n &\definedas \frac{1}{n^p}\\
                \sqrt[n]{\abs{a_n}} &= \pair{\frac{1}{\sqrt[n]{n}}}^p \fromto \pair{\frac{1}{1}}^p = 1\tag{$n\fromto\infty$}\\
                \sum_{n=1}^{\infty} \frac{1}{n^p}&\text{ divergiert für $p=1$ und konvergiert für $p>1$}\\
                \impl &\text{ keine Aussage möglich}\qedhere
            \end{align*}
        \end{proof}
        \begin{proof}[Beweis (i)]
            Sei
            \begin{align*}
                \hat{q}&\definedas \limsup \sqrt[n]{\abs{a_n}} < 1
                \intertext{Wähle $\varepsilon\definedas \frac{1-\hat{q}}{2} > 0$}
                \annot{\impl}{\ref{lemma:limsup-charak}} \sqrt[n]{\abs{a_n}} &< \hat{q} + \varepsilon = \frac{1+\hat{q}}{2}\text{ für fast alle $n$}\\
                \impl \exists n_{0}\in\N\colon \sqrt[n]{\abs{a_n}} &\leq q\quad\forall n\geq n_0\\
                \equivalent \abs{a_n} &\leq q^n\quad\forall n\geq n_0\\
                \intertext{Das heißt $\sum_{n=0}^{\infty} q^n$ ist eine konvergente Majorante für $\sum a_n$}
                \impl \sum_{n=0}^{\infty} a_n&\text{ ist absolut konvergent}\qedhere
            \end{align*}
        \end{proof}
        \begin{proof}[Beweis (ii)]
            Sei
            \begin{align*}
                \hat{q}&\definedas \limsup_{\ntoinf} \sqrt[n]{\abs{a_n}} > 1\\
                \varepsilon &\definedas \frac{\hat{q}-1}{2}>0\\
                q&\definedas \hat{q}-\varepsilon = \frac{1+\hat{q}}{2} > 1\\
                \impl \sqrt[n]{\abs{a_n}} &> \hat{q}-\varepsilon \definedasbackwards q > 1\tag{für unendlich viele $n$}\\
                \impl \abs{a_n} &> q^n\tag{für unendlich viele $n$}\\
                \impl (a_n)_n&\text{ keine Nullfolge}
            \end{align*}
            Somit konvergiert $\sum a_n$ nicht.
        \end{proof}
    \end{satz}

    \newpage

    \begin{definition}[Umordnung von Reihen] % Definition 9
        Seien
        \begin{align*}
            \sum_{n=0}^{\infty} a_n\quad \sum_{n=0}^{\infty} b_n
        \end{align*}
        Reihen mit Gliedern $a_n, b_n\in\R$, $n\in\N_0$. Wir nennen $\sum_{n=0}^{\infty} b_n$ eine Umordnung von $\sum_{n=0}^{\infty} a_n$, falls eine Bijektion
        \begin{align*}
            \sigma: \N_0 \fromto \N_0
        \end{align*}
        existiert mit $b_n = a_{\sigma(n)}~\forall n\in\N_0$.\\
        Ähnlich für Reihen
        \begin{align*}
            \sum_{n=1}^{\infty} a_n\quad \sum_{n=1}^{\infty} b_n
        \end{align*}
        $\sum_{n=1}^{\infty} b_n$ Umordnung von $\sum_{n=1}^{\infty} a_n$, falls Bijektion $\sigma: \N \fromto\N$ existiert mit $b_n = a_{\sigma(n)}$.
    \end{definition}

    \begin{definition}[Unbedingte Konvergenz] % Definition 10
        Eine Reihe $\sum_{n=0}^{\infty} a_n$ heißt unbedingt konvergent, falls jede Umordnung $\sum_{n=0}^{\infty} b_n$ von dieser Reihe ebenfalls konvergiert und die selbe Summe hat.\\
        Andernfalls heißt $\sum_{n=0}^{\infty} a_n$ bedingt konvergent.
    \end{definition}

    \begin{satz}[Direcklet 1837] % Satz 11
        Eine Reihe $\sum_{n=0}^{\infty} a_n$, $a_n\in\R$ ist absolut konvergent genau dann, wenn sie unbedingt konvergiert.
        \begin{proof}
            \anf{$\impl$} Sei
            \begin{align*}
                \sum_{n=0}^{\infty} a_n\text{ absolut konvergent}\\
                \impl \sum_{n=0}^{\infty} \abs{a_n}\text{ konvergent}\\
                \equivalent \sum_{n=0}^{\infty} \abs{a_n} < \infty
                \intertext{Wir wenden das Cauchy-Kriterium an}
                \forall \varepsilon>0~\exists N\in\N\colon \sum_{j=n+1}^{n+p} \abs{a_j} < \varepsilon\quad\forall n\geq N, p\in\N\\
                \impl \sum_{j=n+1}^{\infty}\abs{a_j} = \lim_{p\fromto\infty} \sum_{j=n+1}^{n+p} \abs{a_j} \leq \varepsilon\quad\forall n\geq N\tag{3}
                \intertext{Wir definieren}
                s_n \definedas \sum_{j=0}^{\infty} a_j\quad \sum_{n=0}^{\infty} b_n\text{ Umordnung von } s_n\\
                b_n = a_{\sigma(n)}\quad \sigma: \N_0 \fromto\N_0\text{ Bijektion}\\
                t_n \definedas \sum_{j=0}^{n} b_j
                \intertext{Wir wissen $s_n\fromto s$. Zu zeigen: $t_n\fromto s$}
                \set{1,2,\dots, N} \subseteq \set{\sigma(1), \sigma(2), \dots, \sigma(M)}\tag{Nehmen $M\in\N$}\\
                \intertext{Ist dann $n\geq M$, dann ist}
                \set{a_1, a_2, a_3, \dots, a_N}\subseteq \set{b_1, b_2, \dots b_M} = \set{a_{\sigma(1)}, a_{\sigma(2)}, \dots, a_{\sigma(M)}}\\
                \impl\text{ Alle Glieder $a_1, \dots, a_n$ in der Summe $s_n$ treten in $t_n = t_1 + t_2 + \dots + t_n$ auf}\\
                \impl\text{ Diese Terme heben sich in $s_n-t_n$ gegenseitig auf, sofern $n\geq M$ ist}\\
                \impl \abs{s_n-t_n} \leq \sum_{j\geq N+1, j=\sigma{k}\text{ für ein }k\in\set{1,\dots, M}}^{} \abs{a_j}\\
                \leq \sum_{j=??}^{\infty} \abs{a_j} \leq \varepsilon\\
                \impl s_n - t_n \fromto 0\text{ für }\ntoinf
            \end{align*}
            Da $(s_n)_n$ gegen $s$ konvergiert, konvergiert auch $(t_n)_n$ gegen $s$. Somit konvergiert $\sum_{n=0}^{\infty} b_n$ und hat die selbe Summe wie $\sum_{n=0}^{\infty} a_n$.\\[10pt]
            \anf{$\Leftarrow$} Angenommen $\sum_{n=0}^{\infty} a_n$ ist unbedingt konvergent, aber nicht absolut konvergent.
            \begin{align*}
                p_n &\definedas (a_n)_{+} \definedas \max\pair{0, a_n}\\
                q_n &\definedas (a_n)_{-} \definedas \max\pair{0,-a_n} = -\min\pair{0,a_n}\\
                \impl \abs{a_n} &= p_n + q_n\quad\forall n\in\N_0\\
                \intertext{Wir haben $\sum_{n=0}^{\infty} \abs{a_n}$ konvergiert, aber $\sum_{n=0}^{\infty} p_n = \infty$}
            \end{align*}
            Behauptung: $\sum_{n=0}^{\infty} p_n = \infty$ und $\sum_{n=0}^{\infty} q_n = \infty$. Angenommen $0\leq \sum_{n=0}^{\infty} p_n < \infty$.
            \begin{align*}
                \impl \sum_{n=0}^{\infty} \pair{p_n - a_n}\text{ konvergiert}\\
                \impl \sum_{n=0}^{\infty} a_n < \infty
                \intertext{Da $\abs{a_n} = p_n + q_n$}
                \impl \sum_{n=0}^{\infty} \abs{a_n} = \sum_{n=0}^{\infty} \pair{p_n+q_n} = \sum_{n=0}^{\infty} p_n + \sum_{n=0}^{\infty} q_n < \infty\\
                \text{Widerspruch zu } \sum_{n=0}^{\infty} b_n\text{ ist nicht absolut konvergent}
            \end{align*}
            Jetzt setze $r_0=0$ und bestimme induktiv $(r_n)_n~r_n < r_{n+1}$ mit $p_0 + p_1 + \dots + p_{r_n} > n + q_0 + q_1 + \dots + q_n~\forall n\in\N$.
            $r_q\definedas$ kleinste natürliche Zahl mit $p_0 + p_q + \dots + p_{r_1} > 1 + q_? + q_1$.\\
            $r_2\definedas$ kleinste natürliche Zahl $\geq r_1 + 1$: $p_0 + \dots + p_{r_2} > 2 + q_0 + q_1 + q_2$.\\
            Machen induktiv weiter: Gegeben $r_n$ wähle $r_{n+1} =$ kleinste natürliche Zahl $\geq r_n + 1$ mit $p_0 + p_1 + \dots + p_{r_{n+1}} > n + q_0 + q_1 + \dots + q_n$.\\[10pt]
            Umordnung $p_0 - q_0 + p_1 + \dots + p_{r_1} - q_1 + p_{r_{1+1}} + \dots + p_{r_2} - q_2 + p_{r_{2+1}} + \dots + p_{r_3} - q_3 + \dots$. Diese Umordnung divergiert gegen $+\infty$.
        \end{proof}
    \end{satz}

    \newpage

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 14. Dezember 2023
    %%%%%%%%%%%%%%%%%%%%%%%%

    \begin{satz}[Nach Riemann 1854]
        \marginnote{[14. Dez]}
        Ist $\sum_n a_n$ konvergent, aber nicht absolut konvergent. Dann gibt es zu jedem $c\in\R$ eine Umordnung $\sum_{n}^{} b_n$ von $\sum_{n}^{} a_n$ so, dass $\sum_n b_n$ konvergiert und den Wert $c$ hat ($\sum_{n} b_n = c$).

        \begin{proof}
        (Später)
        \end{proof}
        % Skizze zu Riemann-Satz
    \end{satz}

    \newpage


    \section{[*] $\R^d$, Konvergenz im $\R^d$, die komplexen Zahlen $\C$ und der Raum $\C^d$}

    \subsection{[*] Der Raum $\R^d$ und Normen}

    \thispagestyle{pagenumberonly}

    \begin{definition}
        \begin{align*}
            \R^d &\definedas\text{ Vektorraum der reellen $d$-Tupel}\\
            &=\set{\pair{x_1, x_2, \dots, x_d} ~\middle|~ x_j\in\R,~ j=1,\dots,d }\\
        \end{align*}
    \end{definition}

    \begin{notation}[Linearkombination von Vektoren]
        Es sei
        \begin{align*}
            x&= \pair{x_1, \dots, x_d}\\
            y&= \pair{y_1, \dots, y_d}
            \intertext{und $\alpha, \beta \in \R$, dann gilt}
            \alpha x + \beta y &\definedas \pair{\alpha x_1 + \beta y_1, \alpha x_2 + \beta y_2, \dots, \alpha x_d + \beta y_d}
        \end{align*}
    \end{notation}

    \begin{notation}[Vektorschreibweise]
        \begin{align*}
            x = \begin{pmatrix}
                    x_1 \\ \vdots \\ x_d
            \end{pmatrix}
        \end{align*}
    \end{notation}

    \horizontalline
    Im $\R$ haben wir Konvergenz über den Betrag definiert. Im $\R^d$ benötigen wir daher ein ähnliches Konzept. Wir betrachten dafür zunächst einige Beispiele solcher \textit{Normen}.

    \begin{beispiel}[Euklidische Länge eines Vektors]
        Für $d=2$ gilt für die euklidische Länge $\norm{x}$ eines Vektors $x\in\R^2$
        \begin{align*}
            \norm{x}^2 &= (x_1)^2 + (x_2)^2\\
            \norm{x} &= \sqrt{(x_1)^2 + (x_2)^2}
        \end{align*}
        Allgemein gilt
        \begin{align*}
            \norm{x} &\definedas \sqrt{\pair{\sum_{j=1}^{d} (x_j) ^2}}\tag{$x\in\R^d$}
            \intertext{Wir schreiben auch}
            \norm{x}_2 &\definedas \sqrt{\pair{\sum_{j=1}^{d} (x_j) ^2}}\tag{$x\in\R^d$}
        \end{align*}
    \end{beispiel}

    \begin{beispiel}[Andere Normen]
        Neben der euklidischen lassen sich noch weitere Normen definieren. Zum Beispiel
        \begin{align*}
            \norm{x}_1 &\definedas \sum_{j=1}^{d} \abs{x_j} \tag{Manhattan-Norm}\\
            \norm{x}_{\infty} &\definedas \max_{1\leq j \leq d} \abs{x_j}\tag{Maximums-Norm}
        \end{align*}
    \end{beispiel}

    \begin{definition}[Norm] % Definition 1
        Eine Norm auf $\R^d$ (oder einem reellen Vektorraum) ist eine Abbildung
        \begin{align*}
            \norm{.}: \R^d\fromto \R
        \end{align*}
        mit folgenden Eigenschaften:
        \begin{enumerate}[label=\alph*)]
            \item $\norm{x} \geq 0~\forall x\in\R^d$ sowie $\norm{x} = 0\impl x=0$
            \item $\forall\lambda\in\R,~x\in\R^d\colon \norm{\lambda x} = \abs{\lambda}\cdot\norm{x}$
            \item $\forall x,y\in\R^d\colon\norm{x+y} \leq \norm{x} + \norm{y}$\quad\text{(Dreiecksungleichung)}
        \end{enumerate}
    \end{definition}

    \begin{bemerkung}
        Dass a), b) und c) für $\norm{\cdot}_1$ und $\norm{\cdot}_{\infty}$ gelten, ist einfach zu zeigen. Außerdem sind a) und b) für $\norm{\cdot}_2$ einfach zu zeigen, c) ist tricky. (Übung)
    \end{bemerkung}

    \begin{definition}[Äquivalenz von Normen]
        2 Normen $\norm{\cdot}_a$ und $\norm{\cdot}_b$ sind äquivalent, falls
        \begin{align*}
            \exists c_1, c_2\in\R\colon c_1\cdot\norm{x}_a \leq \norm{x}_b \leq c_2 \norm{x}_a\quad\forall x\in V
        \end{align*}
    \end{definition}

    \begin{beispiel}[Äquivalenz von euklidischer und Maximums-Norm]
        \label{beispiel:norm-equiv}
        Wir zeigen, dass $\norm{\cdot}_{\infty}$ und $\norm{\cdot}_{2}$ äquivalent sind.
        \begin{align*}
            \abs{x_k} &\leq \sqrt{\sum_{j=1}^{d} \abs{x_j}^2} = \norm{x}_2\tag{$1\leq k \leq d$}\\
            \impl \norm{x}_{\infty} &= \max_{k=1,\dots, d} \abs{x_k} \leq \norm{x}_2\tag{1}
            \intertext{Umgekehrt}
            \norm{x}_2^2 = \sum_{j=1}^{d} \abs{x_j}^2 &\leq \sum_{j=1}^{d} \pair{\max_{k=1,\dots, d}\pair{\abs{x_k}}}^2 = d \cdot \norm{x}_{\infty}^2\\
            \impl \norm{x}_2 &\leq \sqrt {d}\cdot \norm{x}_{\infty}\tag{2}
            \intertext{Mit (1) und (2) gilt dann}
            \impl \frac{1}{\sqrt{d}}\cdot \norm{x}_2 &\leq\norm{x}_{\infty} \leq \norm{x}_2
        \end{align*}
    \end{beispiel}

    \begin{uebung}
        Weisen Sie die Äquivalenz von $\norm{x}_1$ und $\norm{x}_\infty$ analog zu Beispiel~\ref{beispiel:norm-equiv} nach.
    \end{uebung}

    \subsection{[*] Konvergenz im $\R^d$}

    \begin{bemerkung}[Abstand zwischen 2 Vektoren im $\R^d$]
        Zu jeder Norm auf $\R^d$ (oder reellen Vektorräumen) definieren wir den Abstand von 2 Vektoren $x,y\in\R^d$ als $\norm{x-y}$.
        \begin{align*}
            d(x,y) &\definedas \norm{x-y}
            \intertext{Mit $z$ als weiterem Vektor gilt}
            \norm{x-y} &= \norm{x-z+z-y}\\
            &\leq \norm{x-z} + \norm{z-y}\\
            \norm{x-y} &= \norm{-(y-x)} = \abs{-1}\cdot \norm{y-x} = \norm{y-x}
        \end{align*}
    \end{bemerkung}

    \begin{folgerung}[Mehrdimensionale $\varepsilon$-Umgebung]
        Bisher basierte unser Konvergenz-Begriff auf dem Abstand von $(x_n)_n$ und $x$ und somit auf einer eindimensionalen $\varepsilon$-Umgebung.\\
        Wir verallgemeinern dieses Konzept für eine offene Kugel im $\R^d$ mit $x\in\R^d$
        \begin{align*}
            B_\varepsilon(x) \definedas \set{y\in\R^d\middle |~ \norm{x-y}_2 < \varepsilon}
        \end{align*}
    \end{folgerung}

    \begin{visualisierung}[Zweidimensionale $\varepsilon$-Umgebung]
        Wir formen die Bedingung um
        \begin{align*}
            \norm{x-y}_2 &< \varepsilon\\
            \impl \sqrt{(x_1-y_1)^2 + (x_2 - y_2)^2} &< \varepsilon\\
            \impl \pair{x_1-y_1}^2 + \pair{x_2-y_2}^2 &< \varepsilon^2
        \end{align*}
        In der Visualisierung erhalten wir einen offenen Ball um $x$ mit Radius $\varepsilon$.

        \begin{figure}[H]
            \centering
            \begin{tikzpicture}
                \draw[fill=\rgbcolor{230}{230}{230}, dashed] (0,0) circle (0.75cm);
                \draw[fill=\rgbcolor{230}{230}{230}, dashed] (2,1) circle (0.75cm);
                \draw[->] (-3,0) -- (3,0);
                \draw[->] (0,-3) -- (0,3);
                \draw[->] (0,0) node {$\times$} -- (0.52, 0.52) node[below, pos=0.8] {$\varepsilon$};
                \draw[->] (2,1) node {$\times$} -- (2, 1.75) node[right, pos=0.5] {$\varepsilon$};
                \draw (-0.25, 0.35) -- (-1.5, 0.35) node[left] {$B_{\varepsilon}\pair{(0,0)}$};
                \draw (1.75, 1.35) -- (-1.5, 1.35) node[left] {$B_{\varepsilon}\pair{(x_1,x_2)}$};
                \node at (-0.75,-0.75) {1.};
                \node at (2.75,0.25) {2.};
                \node at (3,-2) {\begin{tabular}{l}
                                     1. $x=(0,0)$ \\ 2. $x=(x_1, x_2)$
                \end{tabular}};
            \end{tikzpicture}
            \caption{Zweidimensionale $\varepsilon$-Umgebungen}
        \end{figure}
    \end{visualisierung}

    \begin{definition}[Konvergenz im $\R^d$] % Definition 2
        Sei $(x_n)_n$ eine Folge in $\R^d$ mit $x_n\in\R^d~\forall n$. Dann konvergiert $(x_n)_n$ gegen $x\in\R^d$, falls
        \begin{alignat*}{2}
            \forall\varepsilon > 0~\exists N\in\N\colon& \norm{x_1-x}_2 <\varepsilon\quad&&\forall n\geq N
            \intertext{Das heißt}
            \forall\varepsilon > 0~\exists N\in\N\colon& x_n\in B_{\varepsilon}(x)\quad&&\forall n\geq N
        \end{alignat*}
    \end{definition}

    \begin{beobachtung}[Konvergenz in $\R$ vs $\R^d$]
        Es sei ${x_n}\in\R^d$ mit $x_n = \pair{x_n^1, x_n^2, \dots, x_n^d}$\footnote{Koordinaten von $(x_n)_n$}. Damit ergeben sich die Folgen $(x_n^1)_n$, $(x_n^2)_n$, \dots, $(x_n^d)_n$ in $\R$.
        Angenommen $(x_n)_n$ konvergiert gegen $x\in\R^d$. Dann konvergieren alle Folgen $(x_n^l)_n$ in $\R$ und $\lim_{\ntoinf} x_n^l = x^l$

        \begin{proof}
            \begin{align*}
                \abs{x_n^{l} - x^{l}}^2 &\leq \sum_{j=1}^{d} \abs{x_n^{j}-x^{j}}^2 = \norm{x_n -x}_2^2\quad \forall l=1,\dots, d\\
                \impl \abs{x_n^l-x^l} &\leq \norm{x_n-x}_2 \fromto 0\text{ für } n\fromto\infty
            \end{align*}
            Also konvergiert $(x_n^l)$ gegen $x^l$ in $\R$ für alle $l=1,\dots,d$.\qedhere
        \end{proof}
    \end{beobachtung}

    \noindent Es gilt sogar die Umkehrung:

    \begin{satz}[Konvergenz im $\R^d$]
        Eine Folge $(x_n)_n$ in $\R^d$ konvergiert genau dann, wenn jede der Koordinatenfolge $(x_n^l)_n$ in $\R$ konvergiert $\forall l=1,\dots, d$.

        \begin{proof}
            ~\\\anf{$\impl$} Gerade gezeigt.\\
            \anf{$\Leftarrow$} Angenommen
            \begin{align*}
                \exists x^l &\definedas \lim_{\ntoinf} x^l_n\quad\forall l=1,\dots, d\\
                \impl \abs{x_n^l - x^l} &\fromto 0 \text{ für }\ntoinf\quad\forall l=1,\dots, d\colon\\
                \intertext{Das heißt}
                \forall\varepsilon > 0~\exists N_l\in\N\colon \abs{x_n^l - x^l} &< \frac{\varepsilon}{\sqrt{d}}\quad\forall n\geq N_{l}
                \intertext{Wir definieren}
                N&\definedas\max\pair{N_1, N_2, \dots, N_d}
                \intertext{Dann gilt $\forall n>N$}
                \norm{x_n-x}^2_2 &= \sum_{j=1}^{d} \abs{x_n^j - x^j}^2 < \sum_{j=1}^{d} \pair{\frac{\varepsilon}{\sqrt{d}}}^2\\
                &= d\cdot\frac{\varepsilon^2}{d} = \varepsilon^2\\
                \impl \norm{x_n-x}_2 &< \varepsilon\quad\forall n\geq N
                \intertext{Wir definieren den Grenzwert}
                x&\definedas (x^1, x^2, \dots, x^d)\quad x^j\definedas \lim_{\ntoinf} x_n^j\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \newpage

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 19. Dezember 2023
    %%%%%%%%%%%%%%%%%%%%%%%%

    \begin{bemerkung}
        \marginnote{[19. Dez]}
        Sei $(a_n)_n\in\R^d$ mit $a_n = \pair{a_n^1, a_n^2, \dots, a_n^d}$. Reihe $\sum_{n=1}^{\infty} a_n = ??$. Wir betrachten die Partialsummen
        \begin{align*}
            s_n &\definedas \sum_{j=1}^{n} a_j
        \end{align*}
    \end{bemerkung}

    \begin{definition}
        $\sum_{n} a_n$ konvergiert, falls $(s_n)_n$ im $\R^d$ konvergiert
    \end{definition}

    \begin{satz}[Cauchy-Kriterium für Konvergenz im $\R^d$]
        Eine Folge $(x_n)_n$ ist genau dann im $\R^d$ konvergent, wenn $(x_n)_n$ eine Cauchy-Folge ist. Das heißt
        \begin{align*}
            \forall\varepsilon > 0~\exists N\in\N\colon \norm{x_n-x_m}_2 < \varepsilon\quad\forall n,m\geq N
        \end{align*}

        \begin{proof}
            \anf{$\impl$} Wie im Fall $\R$.\\
            \anf{$\Leftarrow$} Sei $(x_n)_n$ Cauchy-Folge.
            \begin{align*}
                \impl\text{ Alle Koordinaten } &(x_n^j)_n\text{ sind Cauchy-Folgen in }\R\text{, weil}\\
                \abs{x_n^j-x_m^j} &= \sqrt {\abs{x_n^j-x_m^j}^2} \leq \sqrt {\sum_{l=1}^{d} \abs{x_n^l - x_m^l}^2}\\
                &= \norm{x_1-x_m}_2\\
                \impl x_n &\definedas \lim_{\ntoinf} x_n^j\text{ existiert}\\
                \impl x &= \lim_{\ntoinf} x_n\text{ existiert}\qedhere
            \end{align*}
        \end{proof}

        \begin{proof}[2. Beweis]
            Wir wollen Satz~\ref{satz:bolzano-weierstrass} im $\R^d$ zeigen:
            Jede beschränkte Folge $(x_n)_n$ in $\R^d$ besitzt eine konvergente Teilfolge. ($(x_n)_n$ ist beschränkt, wenn $\exists R\geq 0\colon \norm{x_n}_2 \leq R~\forall n\in\N$ .Bzw., wenn $x_n\in\set{y\in\R^d \middle|~ \norm{y}_2 \leq R}$ (abgeschlossene Kugel mit Radius $R$ um 0).).\\
            \begin{align*}
                \impl \forall j=1,\dots, d\colon (x_n^j)_n\text{ beschränkte Folge im }\R^d\\
                \impl \exists\text{ Teilfolge } (x_n^1)_k\text{ von } (x_n^1)_n\text{, welche in }\R\text{ konvergiert}\\
                \impl \text{ Ausdünnung }\sigma: \N\fromto\N\text{ mit } \sigma(k) < \sigma(k+1)\\
                n_k \definedas \sigma(k)\quad\text{Existenz des Grenzwert} x_1 \definedas \lim_{\ntoinf} x_{\sigma(k)}
                \intertext{Genauso für $\lim (x^2_n)_n$}
                \annot{\impl}{\ref{satz:bolzano-weierstrass}} \exists \kappa\colon \N\fromto\N\colon (x^2_{\kappa(k)})_k\text{ konvergent}
                \intertext{Catch: $(x^1_{\sigma(k)}, x^2_{\sigma(k)})_k$ ist im Allgemeinen keine Teilfolge von $(x^1_n, x^2_n)_n$. Lösung betrachte}
                \pair{x_{\sigma(k)}}_k\text{ Teilfolge von }(x_n)_n\\
                = \pair{x^1_{\sigma(k)}, x^2_{\sigma(k)}, x^3_{\sigma(k)}, \dots, x^d_{\sigma(k)}, }
                \intertext{Mache mit $(x^2_{\sigma(k)})_k$ weiter}
                \annot{\impl}{\ref{satz:bolzano-weierstrass}} \exists\text{ konvergente Teilfolge von } (x^2_{\sigma(k)})_k\\
                \impl\text{ Ausdünnung } \sigma_2: \N\fromto\N\\
                \impl \pair{x^2_{\sigma(\sigma_2(k))}}_k\text{ konvergent}\\
                x_2 \definedas \sigma \circ \sigma_{2}\\
                \impl\text{ Neue Teilfolge } (x_{\kappa_{2}(k)}) = (x^1_{\kappa_{2}(k)},x^2_{\kappa_{2}(k)},x^3_{\kappa_{2}(k)},\dots, x^d_{\kappa_{2}(k)})
                \intertext{mit $\lim_{k\fromto\infty} x^1_{\kappa_{2}(k)}$ und $\lim_{k\fromto\infty} x^2_{\kappa_{2}(k)}$ existent}
            \end{align*}
            Mache induktiv so weiter, nach maximal $d$ Schritten sind wir fertig.\\
            Jede Cauchy-Folge in $\R^d$ ist beschränkt.
            \begin{proof}
                \begin{align*}
                    \varepsilon = 1\\
                    \impl \exists N\colon\norm{x_n-x_m}_2 \leq 1\quad\forall n,m\geq N\\
                    \impl \norm{x_n}_2 = \norm{x_n-x_N+x_N}_2 \leq \norm{x_n-x_N}_2 + \norm{x}_2\quad\forall n\geq N\\
                    < 1 + \norm{x_n}\\
                    \impl \norm{x}_2 \leq \max\pair{\norm{x_1}_2, \norm{x_2}_2,\dots\norm{x_{N-1}}_2, 1+\norm{x_N}_2}
                \end{align*}
            \end{proof}
            Auch: Eine Cauchy-Folge im $\R^d$ ist genau dann konvergent, wenn sie eine konvergente Teilfolge besitzt. (Beweis wie im Fall $d=1$).\\
            Alle bisherigen Konvergenz-Sätze, welche nicht die Anordnung im $\R$ benötigen, übertragen sich auf $\R^d$.\\
            Insbesondere: Reihe $\sum_{n=1}^{\infty} a_n$ ist absolut konvergent, falls $\sum_{n=1}^{\infty} \norm{a_n}_2 < \infty$.\\
            Ist eine Reihe $\sum_{n=1}^{\infty} a_n$ in $\R^d$ konvergent, so konvergieren alle Umordnungen gegen den selben Wert. Und es gilt die Umkehrung! (Satz von Direcklet in $\R^d$)
        \end{proof}
    \end{satz}

    \subsection{[*] Die Komplexen Zahlen}

    Was sind die komplexen Zahlen?\\
    $x^2+1$ ist nie Null $\forall x\in\R$. Wir definieren eine Zahl $i$ mit $i^2=-1$.\\
    Schreiben $x+iy$ mit $x,y\in\R$.
    \begin{align*}
    (x_1 + y_1\cdot i)
        \cdot (x_2 + y_2\cdot i) &= x_1\cdot x_2 + x_1\cdot i\cdot y_2 + i\cdot y_1 \cdot x_2 + (i\cdot y_1)\cdot(i\cdot y_2)\\
        &= x_1\cdot x_2 - y_1\cdot y_2 + \pair{x_1\cdot y_2 + y_1\cdot x_2}\cdot i\\
        (x_1+y_1\cdot i) + (x_2 + y_2\cdot i) &= x_1 + x_2 + \pair{y_1+y_2}\cdot i
    \end{align*}
    Betrachte $\R^2 = \set{(x,y) \middle|~ x,y\in\R}$.
    % Visualisierung: Eukldische Ebene
    \begin{align*}
        z &= (x,y)\\
        z_1 + z_2 &\definedas (x_1, y_1) + (x_2,y_2)\\
        &\definedas (x_1 + x_2, y_1 + y_2)
        \intertext{Wir definieren eine \anf{seltsame} Multiplikation}
        z_1 \cdot z_2 &\definedas (x_1, y_1)\cdot (x_2, y_2)\\
        &= \definedas \pair{x_1 x_2 - y_1 y_2, x_1 y_2 + x_2 y_1}
        \intertext{Wir definieren den Betrag}
        \abs{z} &\definedas\text{ Länge des Vektors } (x,y) = \sqrt {x^2+y^2}\\
        \intertext{Wir nennen}
        x&= \text{ Realteil von } z\\
        y&= \text{ Imaginärteil von } z\\
    \end{align*}

    Man rechnet einfach nach, dass Multiplikation und Addition Assoziativität, Kommutativität und Distributivität erfüllen.
    \begin{align*}
    (1,0)
        \cdot (1,0) &= (1,0)\\
        (0,1) \cdot (0,1) &= (0-1,0) = -(1,0)\\
        z\cdot (1,0) &= (x,y)\cdot(1,0)= (x,y) = z
        \intertext{in $\R^2$}
        (x,y) &= x\cdot e_1 + y \cdot e_2\tag{$e_1 = (1,0)$, $e_2 = (0,1)$}\\
        (e_1)^2 &= e_1\quad (e_2)^2 = -e_1
    \end{align*}
    Wir schreiben $1$ für $e_1$ und $i$ für $e_2$.
    \begin{align*}
        z &= (x,y) = x\cdot e_1 + y\cdot e_2\\
        &= x\cdot 1 + y\cdot i\\
        &= x + y\cdot i
    \end{align*}
    $\C = \R^2$ mit obiger Multiplikation und Addition. Wir identifizieren $\R$ mit $\R\times\set{0}$ als Teilmenge von $\C$.\\
    Was ist das Inverse von $z=x+y\cdot i$?
    \begin{definition}[Komplexe Konjugation]
        $\overline{z} \definedas \overline{x+yi} \definedas x-yi$
    \end{definition}

    \begin{align*}
        z\cdot\overline{z} &= (x+yi) \cdot (x-yi)\\
        &= (x^2-(yi)^2) = x^2+y^2 = \abs{z}^2\\
        \impl \abs{z} &= \sqrt{z\cdot\overline{z}}\\
        \frac{1}{z} &= \frac{\overline{z}}{z\cdot\overline{z}} = \frac{z}{\abs{z}^2} = \frac{x-yi}{x^2+y^2} = \frac{x}{x^2+y^2} - \frac{y}{x^2+y^2}\cdot i
    \end{align*}

    \newpage

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 21. Dezember 2023
    %%%%%%%%%%%%%%%%%%%%%%%%

    \marginnote{[21. Dez]}

    Wie $\R^d$ wollen wir auch $\C^d$ definieren.

    \begin{definition}[Der Raum $\C^d$]
        \begin{align*}
            \C^d &\definedas \set{\pair{z_1, \dots, z_d} ~\middle | ~ z_j \in\C}\\
            u &= \pair{u_1, \dots, u_d} \in\R^d\\
            w &= \pair{w_1, \dots, w_d} \in\R^d\\
            u+w &= \pair{u_1+w_1,\dots,u_d+w_d}\\
            \lambda\cdot u &= \pair{\lambda u_1,\dots,\lambda u_d}\tag{$\lambda\in\C$}
        \end{align*}
        $\C^d$ ist ein komplexer Vektorraum.

        \begin{align*}
            \abs{u} &\definedas \sqrt{\pair{\sum_{j=1}^{d} \abs{u_j}^2}}\tag{Euklidische Länge}\\
            u &= \pair{u_1, \dots, u_d}\\
            &= \pair{x_1+y_1i, x_2 + y_2 i,\dots, x_d + y_d i}\\
            &= \pair{x_1, x_2,\dots,x_d} + \pair{y_1,y_2,\dots,y_d}i\\
            ???
        \end{align*}
    \end{definition}

    \begin{definition}[]
        \begin{align*}
            \overline{u} &\definedas x - yi\quad (u=x+iy, x,y\in\R^d)\\
            \C^d &= \R^{2d}\\[10pt]
            u &= x + yi\\
            x &= \frac{1}{2}\pair{u+\overline{u}}\quad y = \frac{1}{2i}\pair{u-\overline{u}}
        \end{align*}
    \end{definition}

    Zu ?? im $\R^d$
    \begin{align*}
        \norm{x}_2 &= \sqrt{\pair{\sum_{j=1}^{d} \abs{x_j}^2}} \geq c\\
        \norm{\lambda x}_2 &= \sqrt{\pair{\sum_{j=1}^{d} \abs{\lambda x_j}^2}} = \abs{\lambda}\norm{x}_2
    \end{align*}

    Wann gilt die Dreiecksungleichung?\\
    Auf $\R^d$ gibt es ein Skalarprodukt.\\
    \begin{align*}
        \sprod{x,y} &\definedas \sum_{j=1}^{d} x_j\cdot y_j\tag{$x,y\in\R^d$}\\
        \impl \sprod{x,x} &\definedas \sum_{j=1}^{d} \pair{x_j}^2 = \norm{x}^2_2\\
        \norm{x}_2 &= \sqrt {\sprod{x,x}}
        \intertext{Auch}
        \sprod{x_1+x_2,y} &= \sprod{x_1,y} + \sprod{x_2,y}\\
        \sprod{x,y_1+y_2} &= \sprod{x,y_1} + \sprod{x,y_2}\\
        \sprod{\alpha x,y} &= \alpha \sprod{x,y}\\
        \sprod{x,\alpha y} &= \alpha \sprod{x,y}
    \end{align*}

    \begin{uebung}
        Rechnen Sie die vorherigen Eigenschaften des Skalarprodukts nach.
    \end{uebung}

    \begin{align*}
        \norm{x}_2^2 &= \sprod{x,x}\quad\forall x\in\R^d
        \intertext{Es sei $t\in\R$}
        \norm{x+ty}^2_2 &= \sprod{x+ty, x+ty}\\
        &= \sprod{x,x+ty} + \sprod{ty,x+ty}\\
        &= \sprod{x,x} + \sprod{x+ty} + \sprod{ty,x} + \sprod{ty+ty}\\
        &= t\sprod{x,y}\\
        &= \sprod{x,x} + 2t\sprod{x,y} + t^2\sprod{y,y}
        \intertext{Genauso}
        \norm{x-ty}_2^2 &= \sprod{x-ty, x-ty}\\
        &= \sprod{x,x} - 2t\sprod{x,y} + t^2\sprod{y,y}\\
        &= \norm{x}_2^2 t^2 - 2\sprod{x,y}t + \norm{x}_2^2
        \intertext{Sei $y\neq 0$}
        &= \norm{x}_2^2 \cdot\pair{t^2 - \frac{2\sprod{x,y}}{\norm{y}^2} + \pair{\frac{\sprod{x,y}}{\norm{y}^2}}^2 - \pair{\frac{\sprod{x,y}}{\norm{y}^2}}^2} + \norm{x}_2^2\\
        \intertext{Wir erhalten im Sinne eines Polynoms $a = \norm{y}_2^2\quad b= \sprod{x,y}\quad c= \norm{x}_2^2$}
        &= a\cdot\pair{t^2 - \frac{2b}{a}t + \pair{\frac{b}{a}}^2} + c\\
        &= a\cdot\pair{t-b}^2 - \frac{b^2}{a}+c
        \intertext{Da wir am Anfang der Rechnung eine Norm verwendet haben, muss der Ausdruck nicht-negativ sein}
        a\cdot\pair{t-b}^2 - \frac{b^2}{a}+c &\geq 0\quad\forall t\in\R
        \intertext{Das heißt wir müssen haben}
        \frac{b^2}{a} + c &\geq 0\\
        \equivalent b^2 \leq ac\\
        \equivalent \sprod{x,y}^2 &\leq \norm{y}_2^2 \cdot\norm{x}_2^2\\
        \equivalent \abs{\sprod{x,y}} &\leq \norm{y}_2 \norm{x}_2\tag{Cauchy-Schwarzer-Ungl.}
    \end{align*}

    Und ist $y \neq 0$ und gilt $\abs{\prod{x+y}} = \norm{x}_2 \norm{y}_2$. Dann sind $x$ und $y$ linear abhängig. Das heißt
    \begin{align*}
        \exists t\in\R \text{ mit } x = ty
    \end{align*}
    \begin{proof}
        Dann gilt
        \begin{align*}
            b^2 &= ac\quad \frac{b^2}{a} ac = 0\\
            \impl 0 &\leq \norm{x-ty}^2_2 = a\abs{t-b}^2\\
            &= 0 \text{ für $t=b$ }\\
            \impl \norm{x-ty}_2 &= 0 \text{ für } t=b\\
            \impl x-ty &= 0\\
            \impl x&= ty\qedhere
        \end{align*}
    \end{proof}
    Erkentnis: Aus Cauchy-Schwarzer folgt die Dreiecksungleichung für die Euklidische Norm.

    \begin{align*}
        \norm{x+y}_2^2 &= \sprod{x+y,x+y}\\
        &= \sprod{x,x+y}+ \sprod{y,x+y}\\
        &= \sprod{x,x} + 2 \sprod{x,y} + \sprod{y,y}\\
        &= \norm{x}_2^2 + 2\sprod{x,y} + \norm{y}_2^2\\
        &\leq \norm{x}_2^2 + 2\abs{\sprod{x,y}} + \norm{y}_2^2\\
        &\leq \norm{x}_2^2 + 2\norm{x}_2 \norm{y}_2 + \norm{y}^2\\
        &= \pair{\norm{x}_2 + \norm{y}_2}^2\\
        \impl \norm{x+y}_2 &\leq \norm{x}_2 + \norm{y}_2\tag{Dreiecksungleichung für Eukl. Norm}
    \end{align*}

    \noindent Frage: Was passiert, wenn $\norm{x+y}_2 = \norm{x}_2 + \norm{y}_2$?\\
    (Später)

    \newpage


    \section{Polynome}
    \input{Kapitel/Polynome}


    \section{[*] Cauchyprodukt und Exponentialfunktionen}
    \thispagestyle{pagenumberonly}

    \subsection{[*] Cauchyprodukt}
    Frage: Gegeben Reihen $\sum_{n=0}^{\infty} a_n$, $\sum_{n=0}^{\infty} b_n$, beide konvergent. Wie kann man das Produkt $\pair{\sum_{n=0}^{\infty} a_n}\cdot\pair{\sum_{n=0}^{\infty} b_n}$ geschickt berechnen?\\
    \begin{align*}
        u &= \sum_{n=0}^{\infty} a_n = \lim_{n\fromto\infty} s_n\quad s_n \definedas \sum_{l=0}^{n} a_l\\
        v &= \sum_{n=0}^{\infty} b_n = \lim_{n\fromto\infty} t_n \quad t_n \definedas \sum_{j=0}^{n} b_j\\
        \impl u\cdot v &= \lim_{n\fromto\infty} s_n \cdot \lim_{n\fromto\infty} t_n = \lim_{n\fromto\infty} \pair{s_n\cdot t_n}\\[10pt]
        s_n \cdot t_n &= \sum_{l=0}^{n} a_l \cdot \sum_{j=0}^{n} b_j = \sum_{l=0}^{n} \sum_{j=0}^{n} a_l\cdot b_j
    \end{align*}
    Fakt: Indexmenge der Produkte $a_l b_j$ ist $\N_0 \times \N_0$.
    \begin{align*}
        = \set{(l,j):~l,j\in\N_0} &= \N_0\times\N_0
    \end{align*}
    Es gibt (viele) Bijektionen $\sigma: \N_0 \fromto \N_0\times\N_0$ zum Beispiel durch Schrägabzählen.\\
    Frage: Ist $\sigma: \N_0 \fromto \N_0\times\N_0$ eine beliebige Bijektion, gilt dann
    \begin{align*}
        \pair{\sum_{n=0}^{\infty} a_n}\cdot\pair{\sum_{n=0}^{\infty} b_n} &= \sum_{n=0}^{\infty} a_{\sigma_1(n)}\cdot b_{\sigma_2(n)}\\
        \sigma(n) &= \pair{\sigma_1(n), \sigma_2(n)}
    \end{align*}
    Antwort: Im Allgemeinen nein, aber okay, wenn $\sum_{n}^{} a_n$, $\sum_{n}^{} b_n$ absolut konvergent sind.

    \begin{satz} % Satz 1
        \label{satz:cauchyprodukt}
        Seien $\sum_{n=0}^{\infty} a_n$, $\sum_{n=0}^{\infty} b_n$ absolut konvergente Reihen. Dann gilt für jede Bijektion $\sigma: \N_0 \fromto \N_0\times\N_0$
        \begin{align*}
            \pair{\sum_{n=0}^{\infty} a_n} \cdot \sum_{n=0}^{\infty} b_n &= \sum_{n=0}^{\infty} a_{\sigma_1(n)} \cdot b_{\sigma_2(n)}
            \intertext{Das heißt mit $\sigma(n)=\pair{\sigma_1(n), \sigma_2(n)}$}
            c_n &\definedas a_{\sigma_1(n)}\cdot b_{\sigma_2(n)}\\
            u\cdot v &= \sum_{n=0}^{\infty} c_n
            \intertext{mit der Reihe $\sum_{n=0}^{\infty} c_n$ auch absolut konvergent}
        \end{align*}
        Ferner gilt
        \begin{align*}
            u\cdot v &= \sum_{l=0}^{\infty} \pair{\sum_{j=0}^{\infty} a_l\cdot b_j} \tag{Vertikal zuerst}\\
            &= \sum_{j=0}^{\infty} \pair{\sum_{l=0}^{\infty} a_l\cdot b_j}\tag{Horizontal zuerst}
        \end{align*}
        und
        \begin{align*}
            u\cdot v &= \sum_{k=0}^{\infty} \pair{\sum_{0\leq j,l~l+j=k}^{} a_l\cdot b_j} \tag{Schräg abzählen}
        \end{align*}

        \begin{align*}
            \sum_{k=0}^{L} \abs{a_{\sigma_1(k)}\cdot b_{\sigma_2(k)}} &\leq \sum_{0\leq l\leq M_L~0\leq j\leq M_L}^{} \abs{a_l\cdot b_j} = \pair{\sum_{l=0}^{M_L} \abs{a_l}} \cdot \pair{\sum_{j=0}^{M_L} \abs{b_j}}\\
            &\leq \pair{\sum_{l=0}^{\infty} \abs{a_l}} \cdot \pair{\sum_{j=0}^{\infty} \abs{b_j}}\\
            M_L &\definedas \max_{0\leq k\leq L}\pair{\max\pair{\sigma_1(k), \sigma_2(k)}}
        \end{align*}
        \marginnote{[11. Jan]}
        Insbesondere gilt
        \begin{align*}
            \pair{\sum_{j=0}^{\infty} a_j}\cdot\pair{\sum_{k=0}^{\infty} b_k} &= \sum_{n=0}^{\infty} \pair{\sum_{j,k\geq 0~j+k=n}^{} a_j\cdot b_k}\\
            &= \sum_{n=0}^{\infty} \pair{a_n b_0 + a_{n-1} b_1 + \dots + a_0 b_n}\tag{Cauchy-Produkt}
        \end{align*}

        %%%%%%%%%%%%%%%%%%%%%%%%
        % 11. Januar 2024
        %%%%%%%%%%%%%%%%%%%%%%%%

        \begin{proof}
            1. Schritt:
            \begin{align*}
                k' \definedas \sum_{j=0}^{\infty} \abs{a_j} &< \infty\\
                k'' \definedas \sum_{k=0}^{\infty} \abs{b_k} &< \infty\\
                n\in\N_0: \pair{\sum_{j=0}^{n} \abs{a_j}}\cdot\pair{\sum_{k=0}^{n} \abs{b_k}}\\
                &= \sum_{j=0}^{n} \sum_{k=0}^{n} \abs{a_j}\abs{b_k} \leq k'\cdot k''\quad\forall n\in\N_0
                \intertext{Sei}
                \sigma: \N_0\fromto\N\times\N
                \intertext{eine beliebige Bijektion. Behauptung 1: $ \sum_{n=0}^{\infty} c_n$ ist absolut konvergent, wobei}
                c_n &\definedas a_{\sigma_1(n)}b_{\sigma_2(n)} = a_j b_k\tag{$j=\sigma_1(n)$, $k=\sigma_2(n)$}
                \intertext{Sei $L\in\N_0$}
                M_L^1 &\definedas \max_{n=0,1,\dots, L}\pair{\sigma_1(n)}\\
                M_L^2 &\definedas \max_{n=0,1,\dots, L}\pair{\sigma_2(n)}\\
                M_L &\definedas \max\pair{M_L^1, M_L^2}\\[10pt]
                \impl \abs{c_n} &\leq \abs{a_j}\abs{b_n} \text{ für } 0\leq j \leq M_L^1, 0\leq n \leq M_L^2\\
                \sum_{n=0}^{L} \abs{c_n} &\leq \sum_{j=0}^{M_L} \sum_{k=0}^{M_L} \abs{a_j}\abs{b_k}\\
                &= \pair{\sum_{j=0}^{M_L} \abs{a_j}}\cdot\pair{\sum_{k=0}^{M_L} \abs{b_k}} \leq k' \cdot k'' < \infty\quad\forall L\in\N_0\\
                \impl \sum_{n=0}^{\infty} \abs{c_n} &= \sup_{L\in\N_0} \sum_{n=0}^{L} \abs{c_n} \leq k'\cdot k''<\infty
                \intertext{Schritt 2:}
                s&\definedas \sum_{n=0}^{\infty} c_n \in\R
                \intertext{unabhängig von der Reihenfolge, in der man die $c_n$ aufsummiert, wegen absoluter und damit unbedingter Konvergenz. Das heißt für jede Bijektion $\kappa: \N_0\fromto\N_0\times\N_0$ ist}
                s &= \sum_{n=0}^{\infty} a_{\kappa_1(n)}b_{\kappa_2(n)}\tag{$\sigma\circ\kappa^{-1}$ Bijektion}
                \intertext{Schritt 3: Wir zeigen, dass}
                s &= \pair{\sum_{n=0}^{\infty} a_n}\cdot\pair{\sum_{n=0}^{\infty} b_n}
                \intertext{Sei $\sigma:\N_0\fromto\N_0\times\N_0$ Bijektion durch Quadratabzählen. ($c_0=a_{0} b_0$, $c_1 = a_1 b_0$, $c_2=a_1, b_1$, $c_3=a_0 b_2$)}
                \text{Partialsumme } \sum_{k=0}^{n} c_k &= \sum_{k=0}^{n} a_{\sigma_1(k)} b_{\sigma_2(k)} \text{ mit $\sigma$ Quadratabzählen }
                \intertext{Wir betrachten die Folge}
                \sum_{j=0}^{L} \sum_{k=0}^{L} a_j b_k
                \intertext{Da $\sum_{j=0}^{L} \sum_{k=0}^{L} a_j b_k$ die Summe der geschlossenen Quadrate ist, ist diese eine Teilfolge von $\sum_{k=0}^{n} c_k$ und beide haben den gleichen Grenzwert.}
                \impl s=\sum_{k=0}^{n} c_k &= \lim_{L\fromto\infty} \sum_{j=0}^{L} \sum_{k=0}^{L} a_j b_k = \lim_{L\fromto\infty} \pair{\sum_{j=0}^{L} a_j}\cdot\pair{\sum_{k=0}^{L} b_k}\\
                &= \pair{\sum_{j=0}^{\infty} a_j}\cdot\pair{\sum_{k=0}^{\infty} b_k}
                \intertext{Schritt 4: Cauchy-Produkt}
                \sum_{n=0}^{L} \sum_{\substack{0\leq j,k\\ j+k=n}}^{} a_j b_k &= \sum_{n=0}^{L} \pair{\sum_{j=0}^{L} a_j b_{L-j}}
                \intertext{ist Teilfolge der Folge $\sum_{n}^{} c_n$ mittels Schrägabzählen}
                \impl \lim_{L\fromto\infty} \sum_{n=0}^{L} \sum_{j=0}^{L} a_j b_{L-j} &= \sum_{n=0}^{\infty} c_{\sigma(n)} = s\qedhere
            \end{align*}
        \end{proof}
    \end{satz}
    \vspace{0.5cm}

    \par\noindent\rule[0.25\baselineskip]{.37\textwidth}{0.4pt}\hfill Einschub: Abzählungen\hfill\rule[0.25\baselineskip]{.37\textwidth}{0.4pt}

    \begin{definition}[Unendliche Mengen]
        Es sei $A_n\definedas\set{1,2,\dots, n}$. Eine Menge $B$ ist unendlich groß, wenn $B\neq\emptyset$ und keine Bijektion $\kappa: A_n \fromto B$ für ein beliebiges $n$ existiert.
    \end{definition}

    \begin{beispiel}[Vergleich von Kardinalitäten unendlicher Mengen]
        Wir wollen zeigen, dass $\linterv{0,1}$ und $\interv{0,1}$ gleich groß sind. Wir können alle Zahlen auf sich selber abbilden außer der 1. Wir versuchen $1\mapsto\frac{1}{2}$, $\frac{1}{2}\mapsto\frac{1}{3}$, $\frac{1}{3}\mapsto\frac{1}{4}$, \dots.\\
        Damit können wir alle rationalen Zahlen, die sich als Bruch mit 1 im Zähler darstellen lassen, verschieben. Wir definieren:
        \begin{align*}
            \sigma: \interv{0,1}&\fromto\linterv{0,1}\\
            x&\mapsto
            \begin{cases}
                \frac{1}{n+1},\quad &x=\frac{1}{n} \text{ mit } n\in\N\\
                x,\quad &x\in\interv{0,1}\exclude(\bigcup_{n\in\N} \frac{1}{n})
            \end{cases}
        \end{align*}
    \end{beispiel}

    \begin{bemerkung}[Beispiel für eine Abzählung von $\N\times\N$]
        \label{bem:abzaehlen-nxn}
        Wir wollen eine bijektive Abbildung $\sigma: \N\fromto\N\times\N$ konstruieren.\\
        Level $l\in\N: A_l = \set{\pair{j,k}: j+k = l+1,~j,k\in\N}$ (schrägen Diagonalen).\\
        Anzahl Punkte in $\N\times\N$ auf Level $l\leq k$ mit
        \begin{align*}
            \sum_{l=1}^{k} l &= \frac{k(k+1)}{2}
            \intertext{Schreibe}
            n &= \frac{k(k+1)}{2} + r\quad r\in\set{0,1,2,\dots, k}, k\in\N
            \intertext{Das ist eine Eindeutige Zerlegung von $\N$. Definiere}
            \sigma{n} &= \pair{\sigma_1(n), \sigma_2(n)}\\
            &\definedas \pair{k-r, r}\\
            \sigma_1(n) &= k-r\\
            \sigma_2(n) &= r
        \end{align*}
    \end{bemerkung}

    \begin{uebung}
        Weisen Sie die Bijektivität der definierten Funktion $\sigma$ aus Bemerkung~\ref{bem:abzaehlen-nxn} nach.
    \end{uebung}

    \par\noindent\rule{\textwidth}{0.4pt}

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 16. Januar 2024
    %%%%%%%%%%%%%%%%%%%%%%%%

    \begin{bemerkung}
        \marginnote{[16. Jan]}
        Letzter Schritt: Cauchy-Produkt:
        \begin{align*}
            \sum_{n=0}^{\infty} &= \sum_{n=0}^{\infty} \sum_{\nu=0}^{\infty} a_{\nu}\cdot b_{n-\nu}\\
            &= \pair{\sum_{j=0}^{n} a_j}\cdot\pair{\sum_{k=0}^{\infty} b_k}
        \end{align*}
    \end{bemerkung}

    \newpage

    \subsection{Exponentialfunktionen}

    \begin{definition}[Exponentialfunktion]
        Es sei $z\in\C$. Dann gilt
        \begin{align*}
            e^z = \exp(z)\definedas \sum_{n=0}^{\infty} \frac{z^n}{n!}
        \end{align*}
        Außerdem ist $z^0=1$.
    \end{definition}

    \begin{satz}[Eigenschaften der Exponentialfunktion]
        \theoremescape
        \begin{enumerate}[label=(\alph*)]
            \item Für alle $z\in\C$ konvergiert die obige Reihe absolut. (Wohldefiniertheit der $\exp$-Funktion)
            \item Es gilt $\exp(z_1)\cdot\exp(z_2) = \exp(z_1+z_2)$. Insbesondere ist $\exp(z)\neq 0~\forall z\in\C$ und $\exp(z)^{-1} = \exp(-z)$.
            \item $\conj{\exp(z)} = \exp(\conj{z})$
            \item $\abs{\exp(z)} = \exp(\Re(z))$
            \item $e^x = \exp(x) > 0\quad\forall x\in\R$
        \end{enumerate}

        \begin{proof}[Beweis (a)]
            Wir zeigen, dass die Reihe absolut konvergiert.
            \begin{align*}
                a_n &= \frac{1}{n!}\cdot z^n
                \intertext{Nach dem Quotientenkriterium (\ref{satz:quotientenkriterium})}
                \abs{\frac{a_{n+1}}{a_n}} &= \frac{z}{n+1}\fromto 0 \text{ für } n\fromto\infty\\
                \impl \sum_{n=0}^{\infty} a_n &= \sum_{n=0}^{\infty} \frac{z^n}{n!}\text{ konvergiert absolut}\qedhere
            \end{align*}
        \end{proof}
        \begin{proof}[Beweis (b)]
            \begin{align*}
                \exp(z_1) \cdot \exp(z_2) &= \pair{\sum_{j=0}^{\infty} \frac{z^j}{j!}} \cdot \pair{\sum_{k=0}^{\infty} \frac{z^k}{k!}} \annot{=}{\ref{satz:cauchyprodukt}} \sum_{n=0}^{\infty} \sum_{\nu=0}^{n} a_{\nu} b_{n-\nu}\\
                &= \sum_{n=0}^{\infty} \sum_{\nu=0}^{n} \frac{(z_1)^{\nu}}{\nu!}\cdot \frac{(z_2)^{n-\nu}}{(n-\nu)!}\\
                &= \sum_{n=0}^{\infty} \frac{1}{n!}\cdot \underbrace{\sum_{\nu=0}^{n} \frac{n!}{\nu!\cdot(n-\nu)!}\cdot (z_1)^{\nu}\cdot (z_2)^{n-\nu}}_{\text{Binomischer Lehrsatz}}\\
                &= \sum_{n=0}^{\infty} \frac{1}{n!}\cdot(z_1+z_2)^n = \exp(z_1 + z_2)\qedhere
                \intertext{Insbesondere}
                \exp(z)\cdot \exp(-z) &= \exp(z-z) = e^0 = 1\\
                \impl \Bigg\{
                \begin{split}
                    \exp(z), \exp(-z) &\neq 0 \quad \forall z\in\C\\
                    \exp(z)^{-1} &= \exp(-z)
                \end{split}
            \end{align*}
        \end{proof}
        \begin{proof}[Beweis (c)]
            \begin{align*}
                \conj{\exp(z)} &= \conj{\sum_{k=0}^{\infty} \frac{z^k}{k!}} = \sum_{k=0}^{\infty} \conj{\frac{z^k}{k!}} = \sum_{k=0}^{\infty} \frac{\conj{z^k}}{k!} = \sum_{k=0}^{\infty} \frac{\pair{\conj{z}}^k}{k!} = \exp(\conj{z})\qedhere
            \end{align*}
        \end{proof}
        \begin{proof}[Beweis (d)]
            \begin{align*}
                \abs{\exp(z)}^2 &= \conj{\exp(z)}\cdot \exp(z) = \exp(\conj{z})\cdot \exp(z)\\
                &= \exp(\conj{z} + z) = \exp(2\cdot \Re(z))\\
                &=\exp(\Re(z)+ \Re(z)) = \pair{\exp(\Re(z))}^2\\[10pt]
                \impl \abs{\exp(z)} &= \abs{\exp(\Re(z))} = \exp(\Re(z))\qedhere
            \end{align*}
        \end{proof}
        \begin{proof}[Beweis (e)]
            \begin{align*}
                \text{Ist } x \geq 0 &\impl \exp(x) = \sum_{n=0}^{\infty} \frac{x^n}{n!}= 1 + \sum_{n=1}^{\infty} \frac{x^n}{n!}\geq 1\\
                \text{Ist } x < 0 &\impl \exp(x) = \frac{1}{\exp(-x)} > 0\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{satz}[Definition von Sinus und Kosinus über Expontentialfunktionen]
        Für $\alpha\in\R$ ist $\abs{\exp(i\alpha)}=1$. Wir setzen
        \begin{align*}
            \cos(\alpha) \definedas \Re (e^{i\alpha}) &= \frac{1}{2} \cdot\pair{e^{i\alpha} + e^{-i\alpha}}\\
            \sin(\alpha) \definedas \Im (e^{i\alpha}) &= \frac{1}{2i}\cdot\pair{e^{i\alpha}-e^{-i\alpha}}
            \intertext{Dann haben wir}
            -1 \leq \cos \alpha &\leq 1\\
            -1 \leq \sin \alpha &\leq 1
            \intertext{Außerdem gilt $\forall \alpha\in\R$}
            \cos(\alpha)^2 + \sin(\alpha)^2 &= 1\\
            \cos(\alpha) + i\cdot\sin(\alpha) &= e^{i\alpha} \tag{Eulersche Gleichung}
        \end{align*}

        \begin{proof}
            Es sei $\alpha\in\R$.
            \begin{align*}
                \abs{\exp(i\alpha)}^2 &= \conj{\exp(i\alpha)}\cdot \exp(i\alpha) = \exp(-i\alpha)\cdot \exp(i\alpha) = \exp(0) = 1\\[10pt]
                \Re(e^{i\alpha}) &= \frac{1}{2}\cdot\pair{e^{i\alpha} + \conj{e^{i\alpha}}} = \frac{1}{2}\cdot\pair{e^{i\alpha} + e^{-i\alpha}} \definedasbackwards \cos \alpha\\
                \Im(e^{i\alpha}) &= \frac{1}{2i}\cdot\pair{e^{i\alpha} - \conj{e^{i\alpha}}}= \frac{1}{2i}\cdot\pair{e^{i\alpha} - e^{-i\alpha}}\definedasbackwards \sin \alpha\\[10pt]
                \impl \abs{\exp(i\alpha)}^2 &= \pair{\Re(\exp(i\alpha))}^2 + \pair{\Im(\exp(i\alpha))}^2\\
                &= \pair{\cos (\alpha)}^2 + \pair{\sin (\alpha)}^2\\[10pt]
                \exp(i\alpha) &= \Re (\exp(i\alpha)) + i\cdot \Im (\exp(i\alpha)) = \cos \alpha + i \cdot \sin \alpha\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \newpage


    \section{[*] Potenzreihen}
    \imaginarysubsection{Potenzreihen}
    \thispagestyle{pagenumberonly}

    Wir untersuchen Reihen der Form $ \sum_{n=0}^{\infty} a_n\cdot z^n$ oder $ \sum_{n=0}^{\infty} a_n \cdot \pair{z-z_0}^n$, $z_0\in\C$ fest, $z\in\C$ oder $\R$, $a_n\in\C$.\\
    Partialsummen:
    \begin{align*}
        s_n(z) &\definedas \sum_{j=0}^{n} a_j\cdot z^j
    \end{align*}
    Frage: Konvergenz?
    \begin{beispiel}
        \begin{align*}
            \exp(z) &\definedas \sum_{n=0}^{\infty} \frac{1}{n!} z^n\\
            &= \sum_{n=0}^{\infty} n! \cdot z^n \text{ konvergiert nur für } z=0
        \end{align*}
    \end{beispiel}

    \begin{definition}[Konvergenzradius]
        \begin{align*}
            R &\definedas \sup \set{\abs{z}: z\in\C \text{ und } \sum_{n=0}^{\infty} a_n \cdot z^n \text{ konvergent } }
        \end{align*}
        $R$ ist der Konvergenzradius.
    \end{definition}

    \begin{satz}
        Die Potenzreihe $ \sum_{n=0}^{\infty} a_n z^n$ konvergiert absolut für jedes $z$ in der Kreisscheibe
        \begin{align*}
            B_R (a) &= \set{z\in\C: \abs{z} < R}
        \end{align*}
        Für jedes $\abs{z} > R$ divergiert $ \sum_{n=0}^{\infty} a_n \cdot z^n$.
        \begin{proof}
            Sei $z_1\neq 0$. $ \sum_{n=0}^{\infty} a_n \cdot z^n$ konvergiert.
            \begin{align*}
                \impl (a_n \cdot z^n) \text{ Nullfolge }\\
                \impl \text{ ist beschränkt }\\
                \impl K\definedas \sup_{n\in\N} \set{a_n z^n} < \infty
                \intertext{Sei $0 < r < \abs{z_1}$, $0 < \theta \definedas \frac{r}{\abs{z_1}} < 1$}
                z &\leq \conj{B_r (a)} = \set{\abs{z} \leq r}\\[10pt]
                \abs{a_n z^n} &= \abs{a_n}\abs{z^n} = \abs{a_n} \cdot \abs{z}^n &= \abs{a_n} \cdot \abs{z}^n \frac{\abs{z}}{\abs{z_1}} ^n\\
                &\leq k \theta^n\quad \forall n \geq 0\\
                \impl \sum_{n=0}^{\infty} k \theta^n \text{ konvergente Majorante für } \sum_{n=0}^{\infty} a_n z^n \text{ sofern } 0 \leq z \leq r < \abs{z}\\
                \impl \sum_{n}^{} a_n z^n \text{ konvergiert absolut }\\[12pt]
                \impl (1) \sum_{n=0}^{\infty} a_n z^n \text{ konvergiert für alle } \abs{z} \leq r\\
                \impl (2) \text{ Angenommen } \sum_{n}^{} a_n z^n \text{ konvergiert für ein } \abs{z} > R\\
                (2) \impl \text{ Widerspruch zu Definition von } R
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{bemerkung}
        Konvergiere $ \sum_{n}^{} a_n z^n$ und $ \sum_{n}^{} b_n z^n$ für $\abs{z} < R$
        \begin{align*}
            \impl \sum_{n=0}^{\infty} \pair{\lambda a_n + \mu b_n} z^n &= \lambda \sum_{n=0}^{\infty} a_n z^n + \mu \sum_{n=0}^{\infty} b_n z^n
        \end{align*}
    \end{bemerkung}

    \begin{bemerkung}
        Konvergieren $ \sum_{n=0}^{\infty} a_n z^n$, $ \sum_{n=0}^{\infty} b_n z^n$ auf $B_R (0)$
        \begin{align*}
            \impl \pair{\sum_{n=0}^{\infty} a_n z^n} \cdot \pair{\sum_{n=0}^{\infty} b_n z^n} = \sum_{n=0}^{\infty} \pair{\sum_{\nu=0}^{\infty} a_{\nu} b_{n-\nu}} z^n \tag{Cauchy-Produkt}
            \intertext{Sei $0 < r < R$ für $\abs{z} \leq r$}
        \end{align*}
    \end{bemerkung}

    \begin{bemerkung}
        Wir können auch Potenzreihen der Form
        \begin{align*}
            \sum_{n=0}^{\infty} a_n z^n, \sum_{n=0}^{\infty} a_n \cdot \pair{z-z_0}^n \text{ mit } a_n\in\R^d \text{ oder } \C^d
        \end{align*}
        betrachten. Wir setzen
        \begin{align*}
            R &= \sup \set{\abs{z}: z\in\C und \sum_{n=0}^{\infty} a_n z^n \text{ konvergent } }
        \end{align*}
    \end{bemerkung}

    \begin{satz} % Satz 2
        Die Potenzreihe $ \sum_{n=0}^{\infty} a_n z^n$ konvergiert absolut $\forall z\in B_R (0)$ und divergiert für $\abs{z} > R$.

        \begin{proof}
            Abschreiben des Beweises von Satz 1.
        \end{proof}
    \end{satz}

    \begin{lemma}
        Konvergiert $ \sum_{n=0}^{\infty} a_n z^n$ für ein $z=z_1 \neq 0$ und ist $0 < r < \abs{z_r}$. So ist $ \sum_{n=0}^{\infty} a_n z^n$ auf $B_r (0) = \set{\abs{z} \leq r}$ beschränkt.\\
        Das heißt $\exists M = M_r \geq 0$ mit $\abs{\sum_{n=0}^{\infty} a_n z^n} \leq M_r~\forall \abs{z} \leq r$

        \begin{proof}
            \begin{align*}
                \theta &\definedas \frac{r}{\abs{z_1}} < 1
                \intertext{Da $ \sum_{n=0}^{\infty}  a_n z_1^n$ konvergiert ist}
                (a_n z_n^n)_n \text{ Nullfolge also beschränkt }
                \impl K &= \sup_{n\in\N_0} \abs{a_n z_1^n} = \sup_{n\in\N} \abs{a_n} \abs{z_1}^n < \infty\\
                \intertext{Ist $\abs{z} < r$}
                \abs{a_n z^n} &= \abs{a_n} \abs{z}^n = \abs{a_n} \abs{z_1}^n \abs{\frac{\abs{z}}{\abs{z_1}}}^n\\
                \impl \abs{\sum_{n=0}^{\infty} a_n z^n} &\leq \sum_{n=0}^{\infty} \abs{a_n z}^n \leq \sum_{n=0}^{\infty} k \theta^n = \frac{k}{1-\theta} < \infty\quad \forall \abs{z} \leq r
            \end{align*}
        \end{proof}
    \end{lemma}

    \begin{lemma} % Lemma 4
        \label{lemma:temp-4}
        Annahmen wie bei vorherigem Lemma.
        \begin{align*}
            \impl \text{ Für alle } 0 &< r < \abs{z_1}\quad\forall k\in\N_0\\
            \text{ existiert } M &= M_k, r\geq 0
            \intertext{mit}
            \abs{\sum_{n=k+1}^{\infty} a_n z^n} &\leq M_{k,r} \abs{z}^{k+1}\quad\forall \abs{z} \leq r
        \end{align*}

        \begin{proof}
            \begin{align*}
                \sum_{n=k+1}^{\infty} a_n z^n \text{ konvergiert auch }\\
                \impl \sum_{n=k+1}^{\infty} a_n z^{n-(k+1)} &= z^{-(k+1)} \sum_{n=k+1}^{\infty} a_n z^n \text{ konvergiert }\\
                \impl \text{ verschobene Reihe } \sum_{n=k+1}^{\infty} a_n z^{n-(k+1)} \text{ konvergiert }\\
                \annot{\impl}{Lemma 3} \text{ Für } 0 < r < z_1  \text{ existiert ein } M = M_{k,r} \geq 0
                \intertext{sodass}
                \abs{\sum_{n=k+1}^{\infty} a_n z^{n-(k+1)}} &\leq M_r\quad\forall \abs{z} \leq r < \abs{z_1}\\
                \text{ (linke Seite) } &= \abs{z^{-(k+1)} \sum_{n=k+1}^{\infty} a_n z^n}\\
                &= \frac{1}{\abs{z}^{k+1}} \abs{\sum_{n=k+1}^{\infty} a_n z^n}\\
                \impl \abs{\sum_{n=k+1}^{\infty} a_n z^n} &\leq M_{k,r} \abs{z}^{k+1}
            \end{align*}
        \end{proof}
    \end{lemma}

    \begin{anwendung}
        \begin{align*}
            \sum_{n=0}^{\infty} a_n z^n &= \underbrace{\sum_{n=0}^{k} a_n z^n}_{s_k (z)} + \underbrace{\sum_{n=k+1}^{\infty} a_n z^n}_{Fehler}\\
            \abs{Fehler} &\leq M_{k,r} \abs{z}^{k+1} \leq M_{k,r} \theta^{k+1} \tag{$\theta = \frac{r}{\abs{z_1}}$}
        \end{align*}
    \end{anwendung}

    \newpage

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 18. Januar 2024
    %%%%%%%%%%%%%%%%%%%%%%%%

    Bessere Version von Lemma~\ref{lemma:temp-4}:

    \begin{align*}
        \varphi(z) &= \sum_{n=0}^{\infty} a_n z^n\\
        \abs{\varphi(z) - \sum_{n=k}^{\infty} a_n z^n} &= \abs{\sum_{n=0}^{k} a_n z^n} \leq M_{r,z} \cdot \abs{z}^{k+1}\quad 0< r < \abs{z_1}
        \intertext{Sei $ \sum_{n=0}^{\infty} a_n z^n$ konvergent für ein $z=z_1\neq 0$}
        \impl \forall~ 0< r < \abs{z_1}\colon \text{ existiert }  M_{r,z_1} &> 0
        \intertext{sodass}
        \forall k\in\N_0\colon \abs{\sum_{n=0}^{\infty} a_n z^n} &\leq M_{r,z_1} \abs{\frac{z}{z_1}}^{k+1}\quad\forall \abs{z} \leq r\\
        \abs{\frac{z}{z_1}} &\leq \frac{\abs{z}}{\abs{z_1}} \leq \frac{r}{\abs{z_1}} = \theta < 1
    \end{align*}

    \begin{proof}
        \begin{align*}
            \sum_{n\geq 0}^{} a_n z_1^n \text{ konvergiert }\\
            \impl \pair{a_n z_1^n}_n \text{ ist Nullfolge }\\
            k &\definedas \sup_{n\geq 0} \abs{a_n z_1^n} &< \infty\\
            \impl \abs{a_n z^n} &= \abs{a_n z_1^n \pair{\frac{z}{z_1}}^n} = \abs{a_n z_1^n} \abs{\frac{z}{z_1}}^n\\
            \abs{\frac{z}{z_1}} &\leq \frac{r}{\abs{z_1}} = \theta < 1\\
            \impl \abs{\sum_{n=k+1}^{\infty} a_n z^n} &= \sum_{n=k+1}^{\infty} \abs{a_n z^n}\\
            &\leq \sum_{n=k+1}^{\infty} K \cdot \abs{\frac{z}{z_1}}^n\\
            &= k\cdot \abs{\frac{z}{z_1}}^{k+1} \cdot \sum_{n=0}^{k} \abs{\frac{z}{z_1}}^n\\
            &= \frac{k}{1-\theta} \abs{\frac{z}{z_1}}^{k+1} = \frac{K}{1-\frac{r}{??}}\cdot ??
        \end{align*}
    \end{proof}

    \begin{satz} % Satz 5
        \marginnote{[18. Jan]}

        Sei $ \sum_{n=0}^{\infty}$ eine Potenzreihe, die für ein $z=z_1\neq 0$ konvergiert.\\
        $(z_j)_j$: Folge $0< \abs{z_j} < \abs{z_1}$, $z_j \fromto 0$, $j\fromto\infty$ mit
        \begin{align*}
            \sum_{n=0}^{\infty} a_n (z_j)^n &= 0\quad\forall j\in\N\\
            \impl a_n &= 0\quad\forall n\in\N_0
        \end{align*}
        \begin{proof}
            Angenommen nicht alle $a_n=0$
            \begin{align*}
                \impl B &\definedas \set{n\in\N_0: a_n \neq 0} \neq \emptyset\\
                \impl B \text{ hat ein kleinstes Element, nennen wir } n_0\\
                \impl a_0 &= a_1 = \dots = a_{n_0-1} = 0\quad a_{n_0}\neq 0\\
                f(z) &= \sum_{n=0}^{\infty} a_n z^n = \sum_{n=n_0}^{\infty} a_n z^n = a_{n_0} z^{n_0} + \sum_{n=n_0 + 1}^{\infty} a_n z^n\\
                f(z_1) &= 0\quad\forall j\quad z_j \neq 0\quad z_j\fromto 0\\
                \impl \abs{a_{n_0} (z_j)^{n_0}} &= \abs{- \sum_{n=n_0 + 1}^{\infty} a_n z_j^n} \leq M_{r, z_1} \pair{\frac{\abs{z_j}}{\abs{z_1}}}^{n+1}\\
                \impl \abs{a_{n_0}} \leq M_{r,z} \abs{z_1}^{-(n_0+1)}\quad \abs{z_j} \fromto 0\quad j\fromto\infty\\
                \impl a_{n_0} &= 0\tag{Widerspruch}
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{satz} % Satz 6
        Sei $ \sum_{n=0}^{\infty} a_n z^{n}$, $ \sum_{n=0}^{\infty} b_n z^n$ welche für ein $z=w\neq 0$ konvergieren.\\
        $(z_j)_j$ Folge in $\C$, $z_1\neq 0$, $\forall i, z_i \fromto 0$\\
        mit $ \sum_{n=0}^{\infty} a_n z^n = \sum_{n=0}^{\infty} b_n z_j^n$ für fast alle $z_j$.\\
        Dann ist $a_n = b_n~\forall n\in\N_0$.
        \begin{proof}
            \begin{align*}
                c_n &= a_n - b_n
                \intertext{\OBDA sind alle $\abs{z_1} < \abs{w}$}
                \impl h(z) &\definedas \sum_{n=0}^{\infty} c_n z^n \text{ konvergiert für } z=w\neq 0\\
                \text{ und } h(z_j) &= 0\quad \forall j\\
                \annot{\impl}{Satz 5} c_n &= 0\quad \forall n\in\N_0 \equivalent a_n = b_n \quad\forall n\in\N_0
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{bemerkung}
        Hatten geg. $ \sum_{n=0}^{\infty} a_n z^n$. Dann ist der Konvergenzradius
        \begin{align*}
            R &= \sup \set{\abs{z} : z\in\C \text{ und } \sum_{n=0}^{\infty} a_n z^n \text{ konvergent } }
        \end{align*}
    \end{bemerkung}

    \begin{satz} % Satz 7
        \begin{align*}
            R &= \frac{1}{\limsup_{n\fromto\infty}\sqrt[n]{\abs{a_n}}}
        \end{align*}

        \begin{proof}
            Schritt 1: Zu zeigen: Für $\abs{z} < R$ konvergiert die Potenzreihe.
            \begin{align*}
                M &= \limsup_{n\fromto\infty}\sqrt[n]{\abs{a_n}}\\
                \impl \forall \varepsilon > 0~\exists N \colon \sqrt[n]{\abs{a_n}} &\leq M+\varepsilon\\
                \impl \forall \varepsilon > 0 \text{ ist } \sqrt[n]{\abs{a_n}} &> M- \varepsilon \text{ für fast alle } n
            \end{align*}
            Schritt 2: Zu zeigen: Für $\abs{z} > R$ konvergiert die Potenzreihe nicht. (Übung)
        \end{proof}
    \end{satz}

    \begin{korollar}
        Die Potenzreihe $ \sum_{n=0}^{\infty} a_n z^n$ und $ \sum_{n=1}^{\infty} n a_n z^{n-1}$ haben den gleichen Konvergenzradius.
        \begin{proof}
            Folgt mit vorherigem Satz und $\sqrt[n]{n}\fromto 1$ für $n\fromto\infty$.
        \end{proof}
    \end{korollar}

    \newpage


    \section{Stetige Funktionen einer reellen (oder komplexen) Variablen}
    \input{Kapitel/Stetigkeit}


    \section{Der Zwischenwertsatz}
    \input{Kapitel/Zwischenwertsatz}


    \section{Der Satz von Weierstraß}
    \input{Kapitel/Satz_Weierstrass}


    \section{Grenzwerte von Funktionen}
    \input{Kapitel/Grenzwerte_Funktionen}


    \section{[*] Gleichmäßige Stetigkeit und gleichmäßge Konvergenz}

    \subsection{Gleichmäßige und Lipschitz-Stetigkeit}
    \thispagestyle{pagenumberonly}

    \begin{definition}[Gleichmäßige Stetigkeit] % Def 1
        Sei $f: D\fromto \R$ (oder $\R^d$) und $D\sbset\K$. $f$ heißt gleichmäßig stetig auf $D$, falls
        \begin{align*}
            \fa\varepsilon > 0\ex\delta\colon \abs{f(x)-f(y)} < \varepsilon\quad\fa x,y\in D \text{ mit } \abs{x-y} < \delta
        \end{align*}
    \end{definition}

    \begin{bemerkung}
        Gleichmäßige Stetigkeit ist nach der Definition eine strengere Eigenschaft als Stetigkeit auf $D$. Das heißt jede gleichmäßig stetige Funktion ist auch stetig, aber nicht umgekehrt.
    \end{bemerkung}

    \begin{beispiel}
        \begin{align*}
            f: \R\fromto\R,~x\mapsto\frac{1}{1+x^2}
        \end{align*}
        ist gleichmäßig stetig. (Übung)
    \end{beispiel}
    \begin{beispiel}
        \begin{align*}
            f: \rinterv{0,1}\fromto \R,~x\mapsto \frac{1}{x}
        \end{align*}
        ist stetig, aber nicht gleichmäßig stetig.
        \begin{proof}
            Für $0 < x < y = 2x$ gilt
            \begin{align*}
                \abs{f(x)-f(y)} &= \abs{\frac{1}{x} - \frac{1}{y}} = \frac{\abs{y-x}}{xy} = \frac{1}{y}\geq 1\qedhere
            \end{align*}
        \end{proof}
    \end{beispiel}

    \begin{definition}[Lipschitz-Stetigkeit]
        Eine Funktion $f: D\fromto\R$ (oder $\R^d$) heißt Lipschitz-stetig, falls
        \begin{align*}
            \ex L\geq 0\colon \abs{f(x)-f(y)} \leq L\cdot\abs{x-y}\quad\forall x,y\in D
        \end{align*}
        Jede Lipschitz-stetige Funktion ist gleichmäßig stetig. $(\delta = \frac{\varepsilon}{L})$
    \end{definition}

    \begin{satz}[Heine, 1872] % Satz 3
        \label{satz:17-3}
        Sei $K\sbset\R$ kompakt und $f: K\fromto\R$ (oder $\R^d$) stetig. Dann ist $f$ gleichmäßig stetig.
        \begin{proof}
            Angenommen $f$ ist nicht gleichmäßig stetig.
            \begin{align*}
                \impl\ex\varepsilon > 0\fa \delta > 0\ex x,y\in &K\colon\abs{x-y} < \delta \text{ und } \abs{f(x)-f(y)} > \varepsilon
                \intertext{Wähle $\delta = \frac{1}{n}$}
                \impl\ex x_n, y_n\sbset K\colon \abs{x_n- y_n} &< \frac{1}{n} \text{ aber } \abs{f(x_n)-f(y_n)} \geq \varepsilon > 0\\
                \impl x_n - y_n &\fromto 0 \text{ für } n\fromto\infty
                \intertext{Da $K$ kompakt $\ex$Konvergente TF $(y_{n_l})_l$ von $(y_n)_n$ nach Satz~\ref{satz:bolzano-weierstrass}}
                y &\definedas \lim_{l\toinf} (y_{n_l}) \text{ existiert in } K
                \intertext{Für eine Teilfolge $(x_{n_l})_l$ von $(x_n)_n$ gilt}
                \abs{x_{n_l} - y} &= \abs{x_{n_l} - y_{n_l} + y_{n_l} - y}\\
                &\leq \underbrace{\abs{x_{n_l} - y_{n_l}}}_{<\frac{1}{n}\fromto 0} + \underbrace{\abs{y_{n_l} - y}}_{\fromto 0}\fromto 0\\
                \impl \abs{f(x_{n_l}) - f(y_{n_l})} &\geq \varepsilon > 0
                \intertext{Aber}
                \abs{f(x_{n_l}) - f(y_{n_l})} &= \abs{f(x_{n_l}) - f(y) + f(y) - f(y_{n_l})}\\
                &\leq \underbrace{\abs{f(x_{n_l}) - f(y)}}_{\fromto 0} + \underbrace{\abs{f(y)-f(y_{n_l})}}_{\fromto 0}
            \end{align*}
            Damit ergibt sich ein Widerspruch zur Stetigkeit von $f$ und $f$ ist damit gleichmäßig stetig.
        \end{proof}
    \end{satz}

    \subsection{[*] Punktweise und gleichmäßige Konvergenz von Funktionenfolgen}

    Wir betrachten Folgen von Funktionen. $f_n: D\fromto \R$ (oder $\R^d$) $\leadsto$ Folge $(f_n)_n$ von Funktionen.

    \begin{definition}[Punktweise Konvergenz] % Def 4
        Eine Funktionenfolge $(f_n)_n$, $f_n: D\fromto\R$ (oder $\R^d$) konvergiert punktweise falls
        \begin{align*}
            \lim_{\ntoinf} f_n(x) \text{ existiert für jedes } x\in D
        \end{align*}
        Das heißt $(f_n(x))_n$ ist eine konvergente Folge $\fa x\in\R$. Dann definieren wir
        \begin{align*}
            f(x) \definedas \lim_{\ntoinf} f_n(x)
        \end{align*}
        eine Funktion $f: D\fromto \R$ (oder $\R^d$). Und sagen $f$ ist der punktweise Limes der Funktionenfolge $f_n(x) \fromto f(x)~\fa x\in D$.
    \end{definition}

    \begin{beispiel}
        Die Funktion
        \begin{align*}
            f_n(x) &= x^n\quad 0 \leq x \leq 1
            \intertext{konvergiert punktweise gegen}
            f(x) &= \begin{cases}
                        0\quad &0 \leq x < 1\\
                        1\quad &x = 1
            \end{cases}
        \end{align*}
    \end{beispiel}

    \begin{beispiel}
        Die Funktion
        \begin{align*}
            f_n(x) &= x^{\frac{1}{n}}\quad 0 \leq x \leq 1
            \intertext{ist stetig und punktweise konvergent gegen}
            f(x) &= \begin{cases}
                        0\quad&x = 0\\
                        1\quad&0 < x \leq 1
            \end{cases}
        \end{align*}
    \end{beispiel}

    \begin{beispiel}
        Die Funktion
        \begin{align*}
            f_n(x) &= \pair{1-x^2}^{\frac{n}{2}}\quad -1 \leq x \leq 1
            \intertext{ist stetig und punktweise konvergent gegen}
            f(x) &= \begin{cases}
                        1\quad&x = 0\\
                        0\quad&0 < \abs{x}\leq 1
            \end{cases}
        \end{align*}
    \end{beispiel}

    \begin{definition}[Gleichmäßige Konvergenz - Weierstraß 1841] % Definition 5
        $D\sbset\R$, Funktionenfolge $f_n: D\fromto\R$ (oder $\R^d$). $(f_n)_n$ konvergiert gleichmäßig gegen $f: D\fromto\R$ (oder $\R^d$) falls
        \begin{align*}
            \fa\varepsilon > 0\ex N\in \N \text{ mit } \abs{f_n(x) - f(x)} < \varepsilon\quad\fa n\geq N, x\in D
        \end{align*}
    \end{definition}

    \begin{bemerkung}
        Also gilt bei gleichmäßiger Konvergenz
        \begin{align*}
            \sup_{x\in D} \abs{f_n(x) - f(x)} &\leq \varepsilon\\
            \impl \lim_{\ntoinf} \sup_{x\in D}\abs{f_n(x) - f(x))} &= 0\\
            \equivalent \limsup_{\ntoinf} \pair{\abs{f_n(x) - f(x)}} &= 0
        \end{align*}
    \end{bemerkung}

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 01. Februar 2024
    %%%%%%%%%%%%%%%%%%%%%%%%

    \begin{notation}[Supremumsnorm]
        \marginnote{[01. Feb]}
        Es sei $f: D\fromto \R$ (oder $\R^d$, $\C$). Dann schreiben wir
        \begin{align*}
            \norm{f}_{\infty} &\definedas \norm{f}_{D,\infty} = \norm{f}_{?}\\
            &= \sup_{x\in D} \abs{f(x)}
        \end{align*}
        Norm auf dem Vektorraum der beschränkten Funktionen auf $D$.
    \end{notation}

    \begin{satz}[Cauchy-Kriterium für gleichmäßige Konvergenz]
        Es sei $(f_n)_n$, $f_n: D\fromto \R$ (oder $\R^d$). Dann konvergiert $(f_n)_n$ genau dann gleichmäßig gegen $f$, wenn
        \begin{align*}
            \fa\varepsilon > 0\ex N\in\N\colon \abs{f_n(x) - f_m(x)} < \varepsilon\quad\forall x\in D, n,m\geq N
        \end{align*}
        \begin{proof}
            \anf{$\impl$}: $f(x) = \biglim{\ntoinf} f_n(x)$ existiert $\fa x\in D$.
            \begin{align*}
                \impl \abs{f_n(x) - f_m(x)} \leq \underbrace{\abs{f_n(x) - f(x)}}_{<\frac{\varepsilon}{2}} + \underbrace{\abs{f(x) - f_n(x)}}_{<\frac{\varepsilon}{2}} < \varepsilon\quad\fa n,m\geq N
            \end{align*}
            unabhängig von $x\in D$.\\
            \anf{$\Leftarrow$}: Für $x\in D$ ist $(f_n(x))_n$ eine Cauchy-Folge. Und $f(x) = \biglim{\ntoinf} f_n(x)$ existiert $\fa x\in D$.
            \begin{align*}
                \abs{f_n(x) - f(x)} &= \lim_{\ntoinf} \abs{f_n(x) - f_m(x)} < \varepsilon\quad n\geq N
                \intertext{Sei $\varepsilon > 0$}
                \impl \ex N\in\N\colon \abs{f_n(x) - f_m(x)} &< \varepsilon\quad\fa n,m\geq N\\
                \impl \abs{f_n(x) - f(x)} &= \lim_{\ntoinf} \abs{f_n(x) - f_m(x)} < \varepsilon\quad\fa n\geq N\\
                \impl \sup_{x\in D} \abs{f_n(x) - f(x)} &\leq \varepsilon\quad\fa n\geq N\\
                \impl (f_n)_n &\text{ geht gleichmäíg gegen } f\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{satz}[Weierstraß 1861] % Satz 7
        \label{satz:17-7}
        Seien $f_n: D \fromto \R$ (oder $\R^d$, $\C$) stetige Funktionen, welche gleichmäßig gegen eine Funktion $f$ konvergieren. Dann ist $f$ stetig!
        \begin{proof}
            Geg. $x_0\in D, x\in D$.
            \begin{align*}
                \abs{f(x) - f(x_0)} &= \abs{f(x) - f_n(x) + f_n(x) - f(x_0)}\\
                &\leq \abs{f(x) - f_n(x)} + \abs{f_n(x) - f_n(x_0)} + \abs{f_n(x) - f(x_0)}
                \intertext{$\frac{\varepsilon}{3}$-Trick}
                \fa\varepsilon > 0\ex N\in \N\colon \abs{f_n(y) - f(y)} < \frac{\varepsilon}{3}\quad\forall y\in D, n\geq N
                \intertext{Wir fixieren $n=N$. Dann ist $f_n$ stetig}
                \impl \text{ Geg. }\varepsilon > 0\ex \delta > 0\colon \abs{f_n(x) - f_n(x)} &< \frac{\varepsilon}{3}\quad \text{ für } \abs{x-x_0} < \delta\\
                \intertext{Für $x\in D$, $\abs{x-x_0} < \delta$ gilt}
                \abs{f(x) - f(x_0)} \leq \abs{f(x) - f_n(x)} + \abs{f_n(x) - f_n(x)} + \abs{f_n(x) - f(x_0)} &< \frac{\varepsilon}{3} + \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \varepsilon\\
                \impl f & \text{ ist stetig } \qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{satz}[Weierstraß' M-Test] % Satz 8
        \label{satz:17-8}
        Eine Reihe $ \sum_{n=0}^{\infty} f_n$ von Funktionen $f_n: D\fromto \R$ (oder $\R^d$) konvergiert gleichmäßig, wenn sie eine konvergente Majorante hat, das heißt $\ex M_n\geq 0, N_0\in \N$ mit
        \begin{align*}
            \abs{f_n(x)} &\leq M_n\quad\forall x\in D, n\geq N_0
            \intertext{und}
            \sum_{n=0}^{\infty} N_n &< \infty
        \end{align*}
        \begin{proof}
            Partialsummen
            \begin{align*}
                s_n(x) &\definedas \sum_{j=0}^{n}  f_j(x)
                \intertext{Wir betrachten $n,m\geq N_0$}
                \abs{s_n(x) - s_m(x)} &= \abs{\sum_{j=m+1}^{n} f_j(x)} \leq \sum_{j=m+1}^{n} \underbrace{\abs{f_j(x)}}_{\leq M_j}\\
                &\leq \sum_{j=m+1}^{n} M_j\\
                \impl \abs{s_n(x) - s_m(x)} &\leq \underbrace{\sum_{j=m+1}^{n} M_j}_{\fromto 0}
                \intertext{Haben}
                \impl \sup_{n\geq m} \sup_{x\in D} \abs{s_n(x) - s_m(x)} &\fromto 0 \text{ für } m\fromto\infty\\
                \equivalent s_{n} \text{ konvergiert gleichmäßig auf } &D
                \intertext{$s_n(x)$ stetig, da endliche Summen von stetigen Funktionen stetig sind}
                \impl s(x) &= \lim_{\ntoinf} s_n(x) \text{ ist stetig nach Satz~\ref{satz:17-7}}\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{anwendung}[Potenzreihen]
        Satz~\ref{satz:17-7} und Satz~\ref{satz:17-8} gelten auch für Funktionen $f_n: D\fromto \C$, $D\sbset \C$. Potenzreihe
        \begin{align*}
            f(x) &= \sum_{n=0}^{\infty} a_n x^n\\
            s_n(x) &= \sum_{j=0}^{n} \underbrace{a_{j} x^j}_{\text{Polynom, daher stetig}}
            \intertext{Wir wollen Weierstraß' M-Test anwenden. Sei $R > 0$ Konvergenzradius der Potenzreihe}
            \impl \forall \abs{z} < R \text{ existiert } f(z) &= \sum_{n=0}^{\infty} a_n z^n
            \intertext{Geg. $\delta > 0, R-\delta > 0$ sei $z_1\in \C$}
            \abs{z_1} &= R - \frac{\delta}{2} < R
            \intertext{Aus der Verbesserung von Lemma~\ref{lemma:temp-4} folgt}
            \ex M \geq 0\colon \abs{\sum_{n=k+1}^{\infty} a_n z^n} &\leq M\cdot \abs{\frac{z}{z_1}}^{k+1}\quad\fa \abs{z}< \abs{z_1} = R - \frac{\delta}{2}\\
            \abs{z} &\leq R- \delta\\
            \impl \frac{\abs{z}}{\abs{z_1}} \leq \frac{R-\delta}{R-\frac{\delta}{2}} = q < 1\\
            \impl \abs{\sum_{n=k+1}^{\infty} a_n z^n} \leq M \cdot q^{k+1}\\
            \impl \abs{s(z) - s_k(z)} &= \abs{\sum_{n=k+1}^{\infty} a_n z^n}\\
            &\leq M \cdot q^{k+1} \fromto 0 \text{ für } k\fromto \infty\\
            \sup_{\abs{z} < R - \delta} \abs{s(z) - s_k(z)} &\leq M \cdot q^{k+1} \fromto 0 \text{ für } k\fromto\infty
            \intertext{Partialsummen}
            s_k(z) &= \sum_{n=0}^{k} a_n z^n \text{ konvergiert gleichmäßig gegen } s(z) \text{ für alle } \abs{z} \leq R-\delta
        \end{align*}
        liefert Stetigkeit.
    \end{anwendung}

    \begin{satz}[Weierstraß] % Satz 9
        \label{satz:17-9}
        Sei $a <b$, $f: \interv{a,b}\fromto \R$ stetig. Dann gilt es existiert eine Folge von Polynomen $(P_n)_n$, welche gleichmäßig auf $\interv{a,b}$ gegen $f$ konvergiert. Das heißt $\norm{f-P_n}_{\infty}  = \biglim{\ntoinf} \sup_{a \leq x \leq b} \abs{f(x) - P_n(x)} = 0$

        \begin{proof}
            O.B.d.A. $a=0$, $b=1$ -- sonst ist $g: \interv{0,1} \fromto \interv{a,b}, x\mapsto (b-a)x + a$ stetig und bijektiv und wir haben $h: \interv{0,1} \fromto \R, x\mapsto h(x) = f(g(x))$.\\
            Def. Bernstein Polynome
            \begin{align*}
                P_n(x) &\definedas \sum_{k=0}^{n} \binom{n}{k} x^k \cdot\pair{1-x}^{n-k} \cdot f\of{\frac{k}{n}}\tag{$n\in\N$}
                \intertext{Haben}
                a)&\quad\sum_{k=0}^{n} \binom{n}{k}x^k \cdot \pair{1-x}^{n-k} = \pair{x+(1-x)}^n = 1\tag{Bernoulli}\\
                b)&\quad \sum_{k=0}^{n} k\binom{n}{k}x^k\cdot (1-x)^{n-k} = n\cdot x\\
                c)&\quad \sum_{k=0}^{n} k\cdot(k-1)\binom{n}{k}x^k \cdot\pair{1-x}^{n-k} = n\cdot(n-1) \cdot x^2\\
                b)&\quad k\binom{n}{k} = k\cdot\frac{n!}{k!\cdot(n-k)!} = n\cdot\frac{(n-1)!}{(k-1)!(n+1-(k-1))!} = n\binom{n-1}{k-1}\\
                \impl \sum_{k=0}^{n} k\binom{n}{k}x^k \cdot (1-x)^{n-k} &= \sum_{k=1}^{n} n \binom{n-1}{k-1} x^k \cdot (1-x)^{n-k}\\
                &= n\cdot x\cdot \sum_{k=1}^{n} \binom{n-1}{k-1} x^{k-1} (1-x)^{n-1-(k-1)}\\
                &= \sum_{j=0}^{n-1} \binom{n-1}{j} x^j \cdot (1-x)^{n-1-j} = nx = 1\\
                c)&\quad \text{ Bernoulli: } k\cdot(k+1) \binom{n}{k} = n\cdot (n-1) \binom{n-2}{k-2}\tag{$k\geq 2$}\\
                \sum_{k=0}^{n} k(k+1) \binom{n}{k} x^k (1-x)^{n-k} &= n(n-1) x^{k-2} \underbrace{\sum_{k=2}^{n} \binom{n-2}{k-2} x^{k-2} (1-x)^{n-2-(k-2)}}_{=(1+(1-x))^{k-2} = 1}
            \end{align*}

            \begin{align*}
                \abs{f(x) - P_n(x)} &= \abs{\sum_{k=0}^{n} \binom{n}{k} x^k\pair{1-x}^{n-k}f(x) - \sum_{k=0}^{n}\binom{n}{k}x^k (1-x)^{n-k} f(\frac{n}{k}) }\\
                &\leq \sum_{k=0}^{n} \binom{k}{k} x^k (1-k)^{n-k} \cdot \abs{f(x)- f\of{\frac{n}{k}}}
                \intertext{Nach dem Satz von Heine ist $f$ stetig auf $\interv{0,1}$ das heißt}
                \fa\varepsilon > 0\ex\delta > 0\colon\abs{f(x)-f(y)} < \varepsilon \text{ für } x,y\in\interv{0,1}, \abs{x-y} < \delta
                \intertext{Teilen Summen in 2 Gebiete auf}
                A_1 &\definedas \set{0 \leq k \leq n: \abs{x-\frac{k}{n}} < \delta}\\
                A_2 &\definedas \set{0 \leq k \leq n: \abs{x-\frac{k}{n}} \geq \delta}\\
                \impl \abs{f(x) - P_n(x)} \leq \underbrace{\sum_{k<A_1}^{} \binom{n}{k} x^k (1-k)^{n-k} \abs{f(x) - f(\frac{k}{n})}}_{\definedasbackwards \delta_1}\\
                + \underbrace{\sum_{k<A_2}^{} \binom{n}{k} x^k (1-k)^{n-k} \abs{f(x) - f(\frac{k}{n})}}_{\definedasbackwards \delta_2}\\
                s_1 < \varepsilon \sum_{k < A1}^{} \binom{n}{k} x^k (1-x)^{n-k} < \varepsilon\\
                \intertext{$S2$}
                \abs{x-\frac{k}{n}} < \delta\quad\equivalent\quad \frac{\abs{x-\frac{k}{n}}}{\delta^2} \geq 1
                \intertext{mit}
                \abs{f(x)-f(\frac{k}{n})} \leq \abs{f(x)} + \abs{f(\frac{k}{n})} \leq 2\cdot\sup_{0\leq x \leq 1} (f(x)) < \infty\\
                \impl s_2 &\leq 2 \cdot\norm{f}_{\infty} \cdot \sum_{k=0}^{n} \binom{n}{k} x^k (1-x)^{n-k} \frac{\abs{x-\frac{k}{n}}}{\delta^2}\\
                &\leq 2 \norm{f}_{\infty} \sum_{k=0}^{n} \binom{n}{k} x^k (1-x)^{n-k} \frac{\abs{x-\frac{k}{n}}}{\delta^2}\\
                &= \frac{2\norm{f}}{\delta^2 \cdot n^2} \sum_{k=0}^{n} \binom{n}{k} x^k (1-x)^{n-k} \abs{nx -k}^2\\
                \impl \sum_{k=0}^{n} \binom{n}{k} x^k (1-x)^{n-k} (k^2)\\
                \vdots\quad ???\\
                \vdots\quad ???\\
                \impl \abs{f(x)-P_n(x)} \leq \varepsilon + \frac{\norm{f}_{\infty}}{2\delta^2 n}\\
                \impl \sup_{0\leq x \leq 1} \abs{f(x) - P_n(x)} \leq \varepsilon + \frac{\norm{f}_{\infty}}{2\delta^2 n}\\
                \impl \limsup_{\ntoinf} \norm{f-P_n}_{\infty} \leq \varepsilon\quad\fa \varepsilon > 0\\
                ????
            \end{align*}
        \end{proof}
    \end{satz}

    \newpage

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 06. Februar 2024
    %%%%%%%%%%%%%%%%%%%%%%%%


    \section{[*] Ableitung (engl. Differention)}
    \thispagestyle{pagenumberonly}

    \subsection{Ableitung als Grenzwert}

    \begin{definition} % Definition 1
        \marginnote{[06. Feb]}
        Es seien $D = \pair{a,b}\sbset\R$, $x\in D$ und $f: D\fromto \R$. $f$ heißt im Punkt $x$ von rechts differenzierbar, falls
        \begin{align*}
            f'_+ &\definedas \lim_{h\fromto 0_+} \frac{f(x+h)-f(x)}{h}
            \intertext{existiert. $f$ ist von links differenzierbar, falls}
            f'_- &\definedas \lim_{h\fromto 0_-} \frac{f(x+h)-f(x)}{h}
        \end{align*}
        existiert. $f$ ist im Punkt $x$ differenzierbar, falls $f'_+$ und $f'_-$ existieren und $f'_+ = f'_-$. Das ist äquivalent zu der Existenz von
        \begin{align*}
            \lim_{\substack{h\fromto 0\\ h\neq 0}} \frac{f(x+h)-f(x)}{h}
        \end{align*}
    \end{definition}

    \begin{satz} % Satz 2
        \label{satz:18-2}
        Sei $a\in\pair{c,d}\sbset\R$. Die Funktion $f: \pair{c,d}\fromto\R$ ist genau dann im Punkt $a$ differenzierbar, wenn $\ex C\in\R$ mit $f(x) = f(a)+C\cdot\pair{x-a} + \varphi\of{x}$ wobei
        \begin{align*}
            \lim_{x\fromto a} \frac{\varphi\of{x}}{x-a} = 0
        \end{align*}
        \begin{proof}
            \anf{$\impl$}: Sei $f$ differenzierbar. Wir wählen $\varphi\of{x} \definedas f(x)-f(a) - f'(a)\cdot\pair{x-a}$ und $C=f'\of{a}$.
            \begin{align*}
                \lim_{x\fromto a} \frac{\varphi\of{x}}{x-a} &= \lim_{x\fromto a} \underbrace{\frac{f(x)-f(a)}{x-a}}_{\fromto f'(a)} - f'(a) = 0
            \end{align*}
            \anf{$\Leftarrow$}: Es gilt $f(x) = f(a)+C\cdot\pair{x-a} + \varphi\of{x}$ und $\frac{\varphi(x)}{x-a}\fromto 0$ für $x\fromto a$
            \begin{align*}
                &\impl \frac{f(x)-f(a)}{x-a} = C + \frac{\varphi(x)}{x-a}\\
                &\impl \abs{\frac{f(x)-f(a)}{x-a} - C} \fromto 0\\
                &\impl \frac{f(x)-f(a)}{x-a}\fromto C\\
                &\impl f \text{ ist in $a$ differenzierbar}\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{korollar}
        \theoremescape
        \label{korollar:abschaetzungen-ableitung}
        \begin{enumerate}[label=(\roman*)]
            \item Wenn $f$ im Punkt $a$ differenzierbar ist, dann ist $f$ im Punkt $a$ auch stetig.
            \item Sei $f'(a) \neq 0$. Dann gilt
            \begin{align*}
                \exists h_0~\forall h=x-a \text{ mit } \abs{h} < h_0,~h\neq 0\colon \abs{f(x)-f(a)}\geq\frac{1}{2}\abs{f'(a)}\cdot\abs{x-a}
            \end{align*}
            \newpage
            \item $\exists h_0$, so dass für alle $x$ mit $\abs{x-a} < h_0,~x\neq a$ gilt
            \begin{enumerate}[label=(\arabic*)]
                \item \fixedspace{6cm}{$\abs{f(x)-f(a)} \leq 2\abs{f'(a)}\cdot\abs{x-a}$} für $f'(a)\neq 0$
                \item \fixedspace{6cm}{$\abs{f(x)-f(a)} \leq \varepsilon\cdot\abs{x-a}$} für $f'(a) = 0$ \quad ($\forall\varepsilon > 0$, $h_0$ ist von $\varepsilon$ abhängig)
            \end{enumerate}
        \end{enumerate}

        \begin{proof}[Beweis (i)]
            Für $x\fromto a$ gilt
            \begin{align*}
                f(x)-f(a) &= C\cdot\underbrace{\pair{x-a}}_{\fromto 0} + \underbrace{\frac{\varphi(x)}{x-a}}_{\fromto 0}\cdot\underbrace{\pair{x-a}}_{\fromto 0}\fromto 0\qedhere
            \end{align*}
        \end{proof}

        \begin{proof}[Beweis (ii)]
            Für $x\fromto a$ gilt
            \begin{align*}
                f(x) &= f(a) + f'(a)\cdot\pair{x-a} + \frac{\varphi(x)}{x-a}\cdot\pair{x-a}\\
                \abs{f(x)-f(a)} &\geq \abs{f'(a)}\cdot\abs{x-a} - \underbrace{\abs{\frac{\varphi(x)}{x-a}}}_{\fromto 0}\cdot\abs{x-a}\geq \frac{1}{2}\cdot\abs{f'(a)}\cdot\abs{x-a}\qedhere
            \end{align*}
        \end{proof}
        \begin{proof}[Beweis (iii)]
        (1)
            Für $x\fromto a$ gilt
            \begin{align*}
                \abs{f(x)-f(a)} &\leq \abs{f'(a)}\cdot\abs{x-a} + \underbrace{\abs{\frac{\varphi(x)}{x-a}}}_{\fromto 0} \cdot \abs{x-a} \leq 2\abs{f'(a)}\cdot\abs{x-a}
                \intertext{(2)}
                \abs{f(x)-f(a)} &= \abs{\underbrace{f'(a)}_{\fromto 0} \cdot \pair{x-a} + \underbrace{\frac{\varphi(x)}{x-a}}_{\fromto 0}\cdot\pair{x-a}} \leq \varepsilon\cdot\abs{x-a}\qedhere
            \end{align*}
        \end{proof}
    \end{korollar}

    \subsection{Ableitungsregeln}

    \begin{satz} % Satz 3
        \label{satz:ableitungsregeln}
        Seien $f, g: (a,b)\fromto \R$ differenzierbar, $\lambda\in\R$, $x\in\pair{a,b}$. Dann gilt
        \begin{enumerate}[label=(\roman*)]
            \item $\pair{f+g}'\of{x} = f'(x)+g'(x)$
            \item $\pair{\lambda\cdot f}'\of{x} = \lambda\cdot f'(x)$
            \item $\pair{f\cdot g}'\of{x} = f'(x)\cdot g(x) + g'(x)\cdot f(x)$\quad\quad(Produktregel)
        \end{enumerate}
        \begin{proof}[Beweis (iii)]
            \begin{align*}
                \pair{f+g}'\of{x} &= \lim_{h\fromto 0} \frac{f(x+h)g(x+h) - f(x)g(x)}{h}\\
                &= \lim_{h\fromto 0} \frac{f(x+h)g(x+h) - f(x+h)g(x) + f(x+h)g(x) - f(x)g(x)}{h}\\
                &= \lim_{h\fromto 0} f(x+h)\cdot \underbrace{\frac{g(x+h)-g(x)}{h}}_{\fromto g'(x)} + \lim_{h\fromto 0} g(x) \cdot \underbrace{\frac{f(x+h)-f(x)}{h}}_{\fromto f'(x)}\\
                &= f(x) \cdot g'(x) + g(x)\cdot f'(x)\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{uebung}
        Beweisen Sie die verbleibenden Aussagen des vorherigen Satzes.
    \end{uebung}

    \begin{satz}[Kettenregel] % Satz 4
        \label{satz:kettenregel}
        Seien $f: \pair{a,b}\fromto \R$ und $g: (c,d)\fromto \R$ Funktionen mit $f\interv{\pair{a,b}} \sbset \pair{c,d}$. Die Funktion $f$ sei im Punkt $x\in\pair{a,b}$ differenzierbar und $g$ sei im Punkt $y\definedas f(x)$ differenzierbar. Dann gilt
        \begin{align*}
            \pair{g\circ f}'(x) = g'(f(x)) \cdot f'(x)
        \end{align*}
        \begin{proof}
            Wir definieren $F(x) \definedas g(f(x))$ und unterscheiden zwei Fälle.\\
            \textsc{Fall 1.} $f'(x) \neq 0$. Nach Korollar~\ref{korollar:abschaetzungen-ableitung} gilt
            \begin{align*}
                \ex h_0, \abs{h} < h_0\colon \abs{f(x+h)-f(x)} &\geq \frac{1}{2}\abs{f'(x)}\abs{h} \neq 0\\
                \lim_{h\fromto 0} \frac{F(x+h)-F(x)}{h} &= \lim_{h\fromto 0} \frac{\pair{F(x+h) - F(x)}\cdot\pair{f(x+h)-f(x)}}{\pair{f(x+h)-f(x)}\cdot h}\\
                &= \lim_{h\fromto 0} \frac{g(f(x+h))-g(f(x))}{f(x+h)-f(x)} \cdot \underbrace{\frac{f(x+h)-f(x)}{h}}_{\fromto f'(x)}
                \intertext{$f(x)=y$ und $f(x+h) = y + \Delta y$}
                \lim_{h\fromto 0} \frac{g(f(x+h))-g(f(x))}{f(x+h)-f(x)} &= \lim_{h\fromto 0} \frac{g(y+\Delta y) - g(y)}{\Delta y}\tag{$\Delta y \neq 0$}\\
                &= \lim_{\Delta y \fromto 0} \frac{g(y+\Delta y) - g(y)}{\Delta y}\\
                &= g'(y) = g'(f(x))\\
                \impl \frac{F(x+h)-F(x)}{h} &\fromto g'(f(x)) \cdot f'(x)
                \intertext{\textsc{Fall 2.} $f'(x) = 0$. Dann gilt nach Korollar~\ref{korollar:abschaetzungen-ableitung}}
                \abs{\frac{g(f(x+h)) - g(f(x))}{h}} &\leq \frac{c\cdot\abs{f(x+h)-f(x)}}{h}\\
                &\leq \frac{c\cdot\varepsilon\cdot \abs{x+h-x}}{h}\\
                &= c\cdot\varepsilon\\
                \intertext{mit $c=\max\set{2\cdot\abs{g'(f(x))}, 1}$ und $\varepsilon$ beliebig klein}
                \impl \lim_{h\fromto 0} \frac{F(x+h)-F(x)}{h} = 0 &= g'\of{f\of{x}} \cdot 0 = g'\of{f\of{x}}\cdot f'\of{x}\\
                \intertext{Damit folgt insgesamt}
                \pair{g\circ f}'(x) &= g'(f(x))\cdot f'(x)\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{satz}[Quotientenregel] % Satz 5
        \label{satz:quotient-ableitung}
        Für zwei differenzierbare Funktionen $u,v$ gilt
        \begin{align*}
            \pair{\frac{v}{u}}' = \frac{v'\cdot u - u'\cdot v}{u^2}
        \end{align*}
        \begin{proof}
            \begin{align*}
                \pair{\frac{v}{u}}' &= \pair{v\cdot\frac{1}{u}}' = v'\cdot \frac{1}{u} + v\cdot\frac{1}{u^2}\cdot u'\cdot (-1) = \frac{v'u - u'v}{u^2}\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{beispiel}[Ableitung der Exponentialfunktion]
        Es sei $a\in\C$, $x\in\R$. Wir wollen $e^{ax}$ ableiten
        \begin{align*}
            \pair{e^{ax}}' &= \lim_{h\fromto 0} \frac{e^{a(x+h)} - e^{ax}}{h} = \lim_{h\fromto 0}e^{ax} \cdot \frac{e^{ah}-1}{h} = e^{ax}\cdot \lim_{h\fromto 0} \frac{e^{ah}-1}{h}\\
            e^{ah} &= \sum_{n=0}^{\infty} \frac{(ah)^n}{n!} = 1 + ah + (ah)^2\cdot\sum_{n=2}^{\infty} \frac{(ah)^{n-2}}{n!}
            \intertext{Wir schätzen den letzten Teil der Gleichung mit $\abs{h} < \frac{1}{\abs{a}}$ ab}
            \abs{ \sum_{n=2}^{\infty} \frac{(ah)^{n-2}}{n!}} &\leq \sum_{n=2}^{\infty} \frac{1}{n!} < e\\
            \impl \pair{e^{ax}}' &= e^{ax}\cdot \lim_{h\fromto 0} \frac{1+ah+(ah)^2\cdot e - 1}{h} = a\cdot e^{ax}\tag{$a\in\C$}
        \end{align*}
    \end{beispiel}

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 08. Februar 2024
    %%%%%%%%%%%%%%%%%%%%%%%%

    \begin{beispiel}[Ableitung von $\sin$ und $\cos$]
        \marginnote{[08. Feb]}
        \begin{align*}
            \pair{\sin x}' &= \pair{\Im e^{ix}}' = \Im \pair{e^{ix}}' = \Im\pair{i\cdot e^{ix}} = \Im\of{i\cdot\pair{\cos x + i\cdot \sin x}} = \cos x
            \intertext{Analog lässt sich zeigen, dass gilt}
            \pair{\cos x}' &= -\sin x
        \end{align*}
    \end{beispiel}
    \begin{beispiel}[Ableitung von $\tan$]
        \begin{align*}
            \pair{\tan x}' &= \pair{\frac{\sin x}{\cos x}}' = \frac{\cos x \cdot \cos x -\pair{-\sin x \cdot \sin x}}{\cos^2 x} = \frac{\cos^2 x + \sin^2 x}{\cos^2 x} = \frac{1}{\cos^2 x}
        \end{align*}
    \end{beispiel}

    \begin{satz}[Ableitung der Umkehrfunktion] % Satz 6
        \label{satz:ableitung-umkehrfunktion}
        Sei $f: \pair{a,b} \fromto \pair{c,d}$ eine bijektive Abbildung, die im Punkt $x\in\pair{a,b}$ differenzierbar ist. Dann ist die Funktion $f^{-1}$ an der Stelle $y=f\of{x}$ differenzierbar und es gilt
        \begin{align*}
            \pair{f^{-1}}'\of{y} = \frac{1}{f'\of{x}}
        \end{align*}
        \begin{proof}
            \begin{align*}
                \pair{f^{-1}}'\of{y} &= \lim_{h\fromto 0} \frac{\overbrace{f^{-1}\of{y+h}}^{\definedasbackwards \xi} - f^{-1}\of{y}}{h} = \lim_{h\fromto 0}\frac{\xi - x}{f\of{\xi} - f\of{x}}\\
                &= \lim_{h\fromto 0} \frac{1}{\frac{f\of{\xi} - f\of{x}}{\xi-x}} = \frac{1}{\lim_{h\fromto 0} \frac{f\of{\xi} - f\of{x}}{\xi-x}}
                \intertext{Wegen der Monotonie und Stetigkeit von $f$ können wir umformen zu}
                &= \frac{1}{\lim_{\xi\fromto x} \frac{f\of{\xi} - f\of{x}}{\xi-x}} = \frac{1}{f'\of{x}}\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{beispiel}[Ableitung des Logarithmus]
        Wir definieren $f\definedas e^x$. Damit gilt
        \begin{align*}
            \log y &= f^{-1}\of{y}\\
            \log\pair{e^x} &= x\\
            \pair{\log y}' &= \frac{1}{\pair{e^x}'_{\lvert y=e^x}} = \frac{1}{\pair{e^x}_{\lvert y=e^x}} = \frac{1}{y}
        \end{align*}
    \end{beispiel}

    \begin{bemerkung}[Ableitung von Potenzen]
        \footnote{In VL erst im nächsten Unterkapitel behandelt}
        \begin{align*}
            \pair{x^{\alpha}}' &= \pair{e^{\log x^{\alpha}}} = \pair{e^{\alpha\log x}}'
            \intertext{Nach Satz~\ref{satz:kettenregel}}
            &= e^{\alpha \log x} \cdot \alpha \cdot \pair{\log x}' = \frac{\alpha x^{\alpha}}{x} = \alpha \cdot x^{\alpha-1}
        \end{align*}
    \end{bemerkung}

    \begin{beispiel}[Ableitung von $\arccos$]
        Es sei $y\in\pair{-1, 1}$. Dann gilt
        \begin{align*}
            \pair{\arccos y}' &= \frac{1}{\pair{\cos x}'_{\lvert \cos x = y}} = \frac{1}{-\sin\of{\arccos\of{y}}}\\
            &= \frac{1}{\pm\sqrt{1-\cos^2\of{\arccos y}}} = \pm \frac{1}{\sqrt{1-y^2}}
        \end{align*}
    \end{beispiel}

    \subsection{[*] Lokale Extrema und Mittelwertsätze}

    \begin{definition}[Lokales Maximum und Minimum] % Definition 7
        Sei $f: \pair{a,b} \fromto\R$. Man sagt $f$ habe in $x\in\pair{a,b}$ ein lokales Maximum (Minimum), wenn ein $\varepsilon > 0$ existiert, so dass
        \begin{align*}
            f\of{x} \underset{(\leq)}{\geq} f\of{\xi}\quad \forall \xi\in\pair{x-\varepsilon, x+\varepsilon}
        \end{align*}
    \end{definition}

    \begin{satz}[Ableitung bei lokalen Extrema]
        \label{satz:ableitung-extrem}
        Sei $f: \pair{a,b} \fromto \R$ differenzierbar und $x\in\pair{a,b}$ ein lokales Extremum. Dann gilt $f'\of{x} = 0$.
        \begin{proof}
            $\ex \varepsilon > 0$, $f\of{\xi} \leq f\of{x}$, $\xi\in\pair{x-\varepsilon, x+\varepsilon}$
            \begin{align*}
                f'_{+}\of{x} &= \lim_{\substack{\xi\fromto x\\ \xi > x}} \frac{f\of{\xi} - f\of{x}}{\xi - x} \leq 0\\
                f'_{-}\of{x} &= \lim_{\substack{\xi\fromto x\\ \xi < x}} \frac{f\of{\xi} - f\of{x}}{\xi - x} \geq 0\\
                \impl f'_{+} &= f'_{-} = 0\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{bemerkung}
        Die Umkehrung gilt nicht. Wir betrachten $f: x\mapsto x^3$ mit $f'(0) = 3x^2 = 0$, aber die Funktion hat an der Stelle $x=0$ kein lokales Maximum oder Minimum.
    \end{bemerkung}

    \begin{bemerkung}
        Sei $f$ auf $\interv{a,b}$ stetig und auf $\pair{a,b}$ differenzierbar. Dann kann das Maximum/Minimum der Funktion auch auf den Intervall-Grenzen $a$ und $b$ liegen, obwohl die Ableitung für diese nicht bestimmbar ist.
    \end{bemerkung}

    \begin{satz}[Satz von Rolle]
        \label{satz:von-rolle}
        Sei $a < b$, $f: \interv{a,b} \fromto \R$ eine stetige Funktion mit $f(a) = f(b)$. Die Funktion $f$ sei in $\pair{a,b}$ differenzierbar. Dann $\ex\xi\in\pair{a,b}$ mit $f'\of{\xi} = 0$.
        \begin{proof}
            ~\\
            \textsc{Fall 1.} $f$ ist eine konstante Funktion. Dann gilt $f' = 0$.\\
            \textsc{Fall 2.} $f$ ist keine konstante Funktion. Das heißt nach Satz~\ref{satz:weierstrass-maximum-minimum} $\exists x$ mit $f\of{x} \neq f\of{a}$. Wenn $f(x) > f(a)$, dann existiert ein lokales Maximum bei $x_0\in\pair{a,b}$ und wenn $f(x) < f(a)$, dann existiert ein lokales Minimum bei $x_0\in\pair{a,b}$. Damit ist $f'\of{x_0} = 0$.
        \end{proof}
    \end{satz}

    \newpage

    \begin{satz}[Mittelwertsatz]
        \label{satz:mittelwertsatz}
        Sei $a < b$, $f:\interv{a,b}\fromto\R$ stetig und in $\pair{a,b}$ differenzierbar. Dann gilt
        \begin{align*}
            \ex\xi\in\pair{a,b}\colon f\of{b} - f\of{a} = f'\of{\xi}\cdot\pair{b-a}
        \end{align*}
        \begin{proof}
            \begin{align*}
                F(x) &\definedas f(x) - \frac{f\of{b}-f\of{a}}{b-a}\cdot\pair{x-a}\\
                F(a) &= f(a) - \frac{f(b)-f(a)}{b-a}\cdot 0 = f(a)\\
                F(b) &= f(b) - \frac{f(b)-f(a)}{b-a}\cdot\pair{b-a} = f\of{a}\\
                \impl F(a) &= F(b)
                \intertext{Damit gilt nach Satz~\ref{satz:von-rolle}}
                \impl \ex\xi \text{ mit } F'\of{\xi} &= 0\\
                \impl f'\of{\xi} - \frac{f\of{b} - f\of{a}}{b-a} &= 0\\
                \impl f(b) - f(a) &= f'\of{\xi}\cdot\pair{b-a}\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{visualisierung}[Geometrische Anschauung des Mittelwertsatzes]
        Der Mittelwertsatz sagt aus, dass es einen Punkt auf jeder differenzierbaren Funktion gibt, dessen Tangente parallel zu einer affin-linearen Funktion durch $f(a)$ und $f(b)$ läuft.
        \begin{figure}[H]
            \centering
            \begin{tikzpicture}
                \draw[->] (0, 0) -- (4, 0);
                \draw[->] (0, 0) -- (0, 4);
                \draw (0, 0.1) -- (0, -0.1) node[below] {$a$};
                \draw (4.21*.6, 0.1) -- (4.21*.6, -0.1) node[below] {$\xi$};
                \draw (5*.6, 0.1) -- (5*.6, -0.1) node[below] {$b$};
                \fill (0,0) circle[radius=1.5pt];
                \fill (5*.6,6*0.6*0.6) circle[radius=1.5pt];
                \draw[scale=0.6, domain=0:5, smooth, variable=\x] plot ({\x}, {(-43/120 *\x*\x*\x*\x+71/20*\x*\x*\x-1337/120*\x*\x+259/20*\x)*0.6});
                \draw[scale=0.6, domain=-1:6, smooth, variable=\x] plot ({\x}, {(\x*6/5)*0.6});
                \draw[scale=0.6, domain=-1:6, smooth, variable=\x, dashed] plot ({\x}, {(\x*6/5+4.35)*0.6});
            \end{tikzpicture}
            \caption{Tangente an der Stelle $x=\xi$\\parallel zur Geraden durch die beiden Punkte}
        \end{figure}
    \end{visualisierung}

    \begin{korollar} % Korollar 10
        Es gilt genau dann $f'(x) = 0$ für alle $x\in\pair{a,b}$, wenn $f(x)$ eine konstante Funktion in $\interv{a,b}$ ist.
        \begin{proof}
            \begin{align*}
                f(x_1) - f(x_2) \annot[{&}]{=}{\ref{satz:mittelwertsatz}} f'\of{\xi}\cdot\pair{x_1 - x_2}\\
                &= 0\cdot\pair{x_1 - x_2}\\
                \impl f(x_1) &= f(x_2)\qedhere
            \end{align*}
        \end{proof}
    \end{korollar}

    \begin{satz} % Satz 11
        \label{satz:18-11}
        Seien $f$ und $g$ stetig auf $\interv{a,b}$ und auf $\pair{a,b}$ differenzierbar. Dann gilt
        \begin{align*}
            \ex\xi\in\pair{a,b}\colon \interv{f(b)-f(a)}\cdot g'\of{\xi} &= \interv{g(b)-g(a)}\cdot f'\of{\xi}
        \end{align*}
        \begin{proof}
            \begin{align*}
                h(t) &\definedas \interv{f(b)-f(a)}\cdot g(t) - \interv{g(b)-g(a)}\cdot f(t)\\
                \impl h(a) &= h(b)\\
                \annot{\impl}{\ref{satz:mittelwertsatz}} \ex \xi \in\pair{a,b} &\text{ mit } h'\of{\xi} = 0\\
                \impl \interv{f(b)-f(a)}\cdot g'\of{\xi} &- \interv{g(b)-g(a)}\cdot f'\of{\xi} = 0\\
                \impl \interv{f(b)-f(a)}\cdot g'\of{\xi} &= \interv{g(b)-g(a)}\cdot f'\of{\xi}\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{notation}[Ableitungen höherer Ordnung] % Definition 11
        Wir definieren für die zweite Ableitung
        \begin{align*}
            f'' &= \pair{f'}'
            \intertext{und allgemein}
            f^{(n)} &= \pair{f^{(n-1)}}'
        \end{align*}
    \end{notation}

    \begin{satz}[Der Taylorsche Satz] % Satz 12
        \label{satz:taylor}
        Es sei $f$ eine reelle Funktion auf $\interv{a,b}$ und $f^{(n-1)}$ sei stetig auf $\interv{a,b}$ und $f^{(n)}$ existiere auf $\pair{a,b}$. Sei $\pair{\alpha,\beta}\subseteq \interv{a,b}$ und
        \begin{align*}
            P_{n-1}(t) &= \sum_{k=0}^{n-1} \frac{f^{(k)}\of{\alpha}}{k!}\cdot\pair{t-\alpha}^k\tag{\footnotemark}
            \intertext{Dann $\ex\xi\in\pair{\alpha,\beta}$ so dass}
            f\of{\beta} &= P_{n-1}\of{\beta} + \frac{f^{(n)}\of{\xi}}{n!}\cdot\pair{\beta-\alpha}^n
        \end{align*}

        \footnotetext{In manchen Lehrbüchern wird auch $T_n\of{f,\alpha}$ als alternative Schreibweise zu $P_{n}\of{t}$ verwendet.}

        %%%%%%%%%%%%%%%%%%%%%%%%
        % 13. Februar 2023
        %%%%%%%%%%%%%%%%%%%%%%%%

        \begin{proof}
            \marginnote{[13. Feb]}
            \begin{align*}
                M&\definedas \frac{f(\beta)-P_{n-1}\of{\beta}}{\pair{\beta-\alpha}^n}\quad\in\R\\
                g(t) &\definedas f(t)-P_{n-1}\of{t} - M \cdot \pair{t-\alpha}^n\quad \alpha\leq t\leq\beta\\
                g\of{\alpha} &= f\of{\alpha} - \underbrace{0 - f\of{\alpha}}_{P_{n-1}\of{\alpha}} - 0 = 0\\
                g'\of{\alpha} &= f'\of{\alpha} - f'\of{\alpha} - 0 = 0\\
                \vdots\\
                g^{(n-1)}\of{\alpha} &= 0\\[10pt]
                g\of{\beta} &= f\of{\beta} - P_{n-1}\of{\beta} - \frac{f\of{\beta} - P_{n-1}\of{\beta}}{\pair{\beta-\alpha}^n}\cdot \pair{\beta-\alpha}^n = 0
                \intertext{1. Schritt}
                g\of{\alpha} &= 0,~g\of{\beta} = 0
                \intertext{Nach Satz~\ref{satz:von-rolle}}
                \impl \ex x_1\colon g'(x_1) &= 0
                \intertext{2. Schritt}
                g'\of{\alpha} &= 0,~g'\of{x_1} = 0\\
                \impl \ex x_2\in\pair{\alpha, x_1}\colon g''(x_2) &= 0\\[10pt]
                g''(\alpha) &= 0,~g''\of{x_2} = 0\\
                \vdots\\
                \impl\ex x_n \in\pair{\alpha, x_{n-1}}\colon g^{(n)}\of{x_n} &= 0\tag{$\xi\definedas x_n$}\\
                f^{(n)}\of{\xi} - 0 - M\cdot n! &= 0\\
                M = \frac{f^{(n)}\of{\xi}}{n!} &= \frac{f\of{\beta}-P_{n-1}\of{\beta}}{\pair{\beta-\alpha}^n}\\
                \equivalent f\of{\beta} - P_{n-1}\of{\beta} &= \frac{f^{(n)}\of{\xi}}{n!}\cdot\pair{\beta-\alpha}^n\\
                f\of{\beta} &= P_{n-1}\of{\beta} + \frac{f^{(n)}\of{\beta}}{n!}\pair{\beta-\alpha}^n\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \newpage

    \begin{bemerkung}
        Der Taylorsche Satz ist eine Verallgemeinerung des Mittelwertsatzes für höhere Ableitungen.
    \end{bemerkung}

    \begin{korollar}[Monotonie] % Korollar 14
        \label{korollar:monotonie}
        Sei $f$ auf $\pair{a,b}$ differenzierbar mit $f' > 0$ ($f' < 0$). Dann ist $f$ streng monoton wachsend (fallend) auf $\pair{a,b}$.
        \begin{proof}
            Seien $x_1, x_2\in\pair{a,b}$ mit $x_2 > x_1$. Nach Satz~\ref{satz:mittelwertsatz} gilt
            \begin{align*}
                f(x_2) - f(x_1) &= \underbrace{f'(\xi)}_{> 0}\cdot\underbrace{\pair{x_2 - x_1}}_{> 0} > 0\qedhere
            \end{align*}
            Der Beweis für fallende Funktionen funktioniert analog.
        \end{proof}
    \end{korollar}

    \begin{bemerkung}[Über Max und Min]
        Es seien $f$ differenzierbare Funktion und $x_0$ lokales Extremum von $f$ und sei $f''\of{x_0}$ existent und positiv (negativ). Dann ist $x_0$ ein lokales Minimum (Maximum).

        \begin{proof}
            \begin{align*}
                f''\of{x_0} &= \lim_{\xi\fromto x_0} \frac{f'\of{\xi} - f'\of{x_0}}{\xi-x_0} > 0\\
                &\impl \ex\varepsilon > 0\colon \frac{f'\of{\xi} - f'\of{x_0}}{\xi-x_0} > 0\quad\forall\xi, 0 < \abs{x_0-\xi} < \varepsilon\\
                &\impl \begin{cases}
                           f'\of{\xi} < 0 \text{ für } \xi < x_0~\leadsto \text{ Funktion fällt}\\
                           f'\of{\xi} > 0 \text{ für } \xi > x_0~\leadsto \text{ Funktion steigt}
                \end{cases}
            \end{align*}
            Da die Funktion vor $x_0$ fällt und danach steigt, ist $x_0$ ein lokales Minimum.
        \end{proof}
    \end{bemerkung}

    \newpage

    \subsection{[*] Die Regel von l'Hospital}

    \begin{satz}[Regel von de l'Hospital] % Satz 16
        \label{satz:l-hospital}
        Seien $f$ und $g$ differenzierbar in $\pair{a,b}$. Sei ferner $g'\of{x} \neq 0$ für alle $x\in\pair{a,b}$ und es gelte
        \begin{align*}
            \frac{f'(x)}{g'(x)} \fromto A \text{ für } x \fromto a\tag{1}
            \intertext{Außerdem gelte}
            f(x) \fromto 0 \text{ und } g(x)\fromto 0 \text{ für } x\fromto a\tag{2}
            \intertext{\underline{oder}}
            g(x)\fromto \infty \text{ für } x\fromto a\tag{2}
            \intertext{Dann gilt}
            \frac{f(x)}{g(x)}\fromto A
        \end{align*}
        Die analoge Behauptung war für $x\fromto b$ oder für $g(x)\fromto -\infty$.

        \begin{bemerkung}
            $g'(a) = 0$ ist bei der Anwendung des Satzes erlaubt.
        \end{bemerkung}

        \begin{proof}
            Sei $A < \infty$
            \begin{align*}
                \impl\ex q > A
                \intertext{Sei $A < r < q$}
                \impl \frac{f'(x)}{g'(x)} < r \text{ für } a < x < a + \varepsilon_0
                \intertext{Nach Satz~\ref{satz:18-11} gilt mit $a < x < y < a + \varepsilon_0$}
                \frac{f(x)-f(y)}{g(x)-g(y)} = \frac{f'(\xi)}{g'(\xi)}  < r
                \intertext{\textsc{Fall 1.} $f(x)\fromto 0, g(x)\fromto 0$ für $x\fromto a$}
                \impl g(y) \neq 0, \text{ weil } g(a) = 0,~g'(a)\neq 0\\
                \lim_{x\fromto a} \frac{\overbrace{f(x)}_{\fromto 0}-f(y)}{\underbrace{g(x)}_{\fromto 0}-g(y)} &= \lim_{x\fromto a} \frac{f(y)}{g(y)} \leq r < q\\
                \impl \fa a < y < a + \varepsilon_0\colon \frac{f(y)}{g(y)} &< q\\
                \impl \lim_{y\fromto a} \frac{f(y)}{g(y)} &< q
                \intertext{\textsc{Fall 1.} $g(x)\fromto\infty$ für $x\fromto a$. Dann gilt mit $a < x < y < a + \varepsilon_0$}
                \frac{f(x)-f(y)}{g(x)-g(y)} &< r\\
                \impl \frac{\frac{f(x)}{g(x)}- \frac{f(y)}{g(x)}}{1 - \frac{g(y)}{g(x)}} &< r\\
                \impl \frac{\frac{f(x)}{g(x)}}{1} &\leq r < q\\
                \impl\fa q > A\colon \frac{f(x)}{g(x)} < q
            \end{align*}
            Sei $A > -\infty$
            \begin{align*}
                \impl\ex p < A, p < r < A\\
                \frac{f(x)-f(y)}{g(x)-g(y)} &= \frac{f'\of{\xi}}{g'\of{xi}} &> r > p\quad a < x < y < a + \varepsilon_0
                \intertext{Mit der gleichen Argumentation wie davor ergibt sich}
                \frac{f(x)}{g(x)} &> p\\
                \impl \frac{f(x)}{g(x)} &\fromto A\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{beispiel}
        \begin{align*}
            \lim_{x\fromto 1_-} \interv{\ln x \cdot \ln\of{1-x}} &= \lim_{x\fromto 1_-} \frac{\ln\pair{1-x}}{\frac{1}{\ln\of{x}}}\\
            &= \lim_{x\fromto 1_-} \frac{\frac{1}{1-x}\cdot\pair{-1}}{-\frac{1}{\ln^2\of{x}} \cdot \frac{1}{x}}\\
            &= \lim_{x\fromto 1_-} \frac{x\cdot\ln^2\of{x}}{1-x}\\
            &= \lim_{x\fromto 1_-} \frac{2\ln\of{x}\cdot \frac{1}{x}}{-1} = 0
        \end{align*}
    \end{beispiel}

    \newpage


    \section{Konvexität}
    \input{Kapitel/Konvexitaet}

    \vfill

    \begin{center}
        \textbf{\LARGE Pause bis zum Sommersemester 2024}
    \end{center}

    \vfill

\end{document}
